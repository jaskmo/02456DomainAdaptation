{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout, Activation, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "import pickle\n",
    "from ourUtils import *\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 20485     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 134,281,029\n",
      "Trainable params: 134,281,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the convolutional part of the VGG16 network \n",
    "vggConv = VGG16(weights='imagenet', include_top=False)\n",
    "vgg_train = False\n",
    "\n",
    "# Input to network\n",
    "vggInput = Input(shape=(224, 224, 3), name='image_input')\n",
    "# Output of convolutional part\n",
    "output_vggConv = vggConv(vggInput)\n",
    "# Label predictive layers. Initialized using glorot (Xavier's), L2 regularization and dropout\n",
    "lpmF = Flatten()(output_vggConv)\n",
    "lpm1 = Dense(4096, activation='relu', kernel_initializer='glorot_normal',\n",
    "            kernel_regularizer=regularizers.l2(0.01))(lpmF)\n",
    "lpm1Dr = Dropout(0.5)(lpm1)\n",
    "lpm2 = Dense(4096, activation='relu', kernel_initializer='glorot_normal',\n",
    "            kernel_regularizer=regularizers.l2(0.01))(lpm1Dr)\n",
    "#lpm2Dr = Dropout(0.5)(lpm2)\n",
    "lpm3 = Dense(5, activation=None, kernel_initializer='glorot_normal')(lpm2)\n",
    "lpmS = Activation('softmax')(lpm3)\n",
    "# Make into single network\n",
    "vggConvSleep = Model(inputs=vggInput, outputs=lpmS)\n",
    "# If conv layers should not be trained: \n",
    "# Maybe this should be excluded\n",
    "\n",
    "\n",
    "#for layer in vggConvSleep.layers[:2]:\n",
    "#    layer.trainable = False\n",
    "#else:\n",
    "#    for layer in vggConvSleep.layers[1].layers[:-2]:\n",
    "#        layer.trainable = False\n",
    "\n",
    "# Optimizer\n",
    "optimize = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# Compile the model\n",
    "vggConvSleep.compile(loss='categorical_crossentropy', optimizer=optimize, metrics=['categorical_accuracy'])\n",
    "\n",
    "# Get model summary\n",
    "vggConvSleep.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_mode = 'source'\n",
    "# training_mode = 'target'\n",
    "# training_mode = 'dann'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29772 images belonging to 5 classes.\n",
      "Found 4807 images belonging to 5 classes.\n",
      "Found 3862 images belonging to 5 classes.\n",
      "Found 2722 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "path = '/home/jaskmo/Documents/programering/02456DomainAdaptation/'\n",
    "if training_mode == 'source':\n",
    "    data_path = path + 'taperImages/pysNetData'\n",
    "    OC_path  = path + 'taperImages/hData'\n",
    "else:\n",
    "    data_path = path + 'taperImages/hData'\n",
    "    OC_path = path + 'taperImages/pysNetData'\n",
    "\n",
    "# batch nr per epoch\n",
    "batchSize = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        data_path + '/train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "#       color_mode='grayscale',\n",
    "#       save_to_dir=dataPath + 'tmpImg')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        data_path + '/validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical',\n",
    "#       color_mode='grayscale'\n",
    "        shuffle=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        data_path + '/test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical',\n",
    "#       color_mode='grayscale')\n",
    "        )\n",
    "\n",
    "# other dataset test generator\n",
    "OC_test_generator = test_datagen.flow_from_directory(\n",
    "        OC_path + '/test',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical',\n",
    "#       color_mode='grayscale')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N1': 0, 'N2': 1, 'N3': 2, 'REM': 3, 'wake': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainStepEpoch = np.floor_divide(train_generator.n, batchSize) #np.floor_divide(len(os.listdir(dataPath + 'train/left/'))*3, batchSize)\n",
    "valStepEpoch = np.floor_divide(validation_generator.n, batchSize) #np.floor_divide(len(os.listdir(dataPath + 'validate/left/'))*3, batchSize)\n",
    "testStepEpoch = np.floor_divide(test_generator.n, batchSize) #np.floor_divide(len(os.listdir(dataPath + 'test/left/'))*3, batchSize)\n",
    "OC_testStepEpoch = np.floor_divide(OC_test_generator.n, batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Number of subjects for each group\n",
    "# num_subjects_physionet = 20\n",
    "# num_subjects_hospital = 17\n",
    "\n",
    "# # Load all data into memory\n",
    "# # Change data path before running !!\n",
    "# data_physionet = pickle.load(open('/home/jaskmo/Documents/DataCollection/sleep-edfx/PickleJar/dataOut.pkl','rb'))\n",
    "# data_hospital = pickle.load(open('/home/jaskmo/Documents/DataCollection/sleep-edfx/PickleJar/hDataOut.pkl', 'rb'))\n",
    "# random_perm_physionet = np.random.permutation(num_subjects_physionet)\n",
    "# random_perm_hospital = np.random.permutation(num_subjects_hospital)\n",
    "# idx_tmp_physionet = random_perm_physionet[range(num_subjects_physionet - 3)]\n",
    "# idx_test_physionet = random_perm_physionet[(num_subjects_physionet - 3):num_subjects_physionet]\n",
    "# idx_tmp_hospital = random_perm_hospital[range(num_subjects_hospital - 3)]\n",
    "# idx_test_hospital = random_perm_hospital[(num_subjects_hospital- 3) : num_subjects_hospital]\n",
    "# inputs_train_phys, targets_train_phys, inputs_val_phys, targets_val_phys, inputs_test_phys, targets_test_phys = get_data_complete(\n",
    "#     idx_tmp_physionet, idx_test_physionet, data_physionet, 'physionet')\n",
    "# inputs_train_hosp, targets_train_hosp, inputs_val_hosp, targets_val_hosp, inputs_test_hosp, targets_test_hosp = get_data_complete(\n",
    "#     idx_tmp_hospital, idx_test_hospital, data_hospital, 'hospital')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',epsilon=0.1, factor=0.3, patience=4, min_lr=0.000001, verbose=1)\n",
    "erl_stop = EarlyStopping(monitor = 'val_loss', min_delta=0.05, patience=7, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_fraq = []\n",
    "class_weights = []\n",
    "#inv_map = {v: k for k, v in train_generator.class_indices.items()}\n",
    "for i in range(train_generator.num_class):\n",
    "    class_fraq.append(len(train_generator.classes[train_generator.classes == i])/train_generator.n)\n",
    "big_class = max(class_fraq)\n",
    "for i in range(train_generator.num_class):\n",
    "    class_weights.append(np.floor_divide(big_class,class_fraq[i]))\n",
    "\n",
    "weights_dic = dict(zip(train_generator.class_indices.values(),class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "930/930 [==============================] - 639s - loss: 53.9402 - categorical_accuracy: 0.8109 - val_loss: 33.3642 - val_categorical_accuracy: 0.8635\n",
      "Epoch 2/80\n",
      "930/930 [==============================] - 637s - loss: 23.8773 - categorical_accuracy: 0.8614 - val_loss: 17.1089 - val_categorical_accuracy: 0.8057\n",
      "Epoch 3/80\n",
      "930/930 [==============================] - 636s - loss: 12.9793 - categorical_accuracy: 0.8787 - val_loss: 10.0137 - val_categorical_accuracy: 0.8232\n",
      "Epoch 4/80\n",
      "930/930 [==============================] - 638s - loss: 7.7431 - categorical_accuracy: 0.8943 - val_loss: 6.1902 - val_categorical_accuracy: 0.8461\n",
      "Epoch 5/80\n",
      "930/930 [==============================] - 639s - loss: 4.8391 - categorical_accuracy: 0.9117 - val_loss: 4.1004 - val_categorical_accuracy: 0.8302\n",
      "Epoch 6/80\n",
      "930/930 [==============================] - 640s - loss: 3.1265 - categorical_accuracy: 0.9278 - val_loss: 2.9007 - val_categorical_accuracy: 0.8226\n",
      "Epoch 7/80\n",
      "930/930 [==============================] - 641s - loss: 2.0723 - categorical_accuracy: 0.9442 - val_loss: 2.1855 - val_categorical_accuracy: 0.8121\n",
      "Epoch 8/80\n",
      "930/930 [==============================] - 641s - loss: 1.4013 - categorical_accuracy: 0.9588 - val_loss: 1.7250 - val_categorical_accuracy: 0.8222\n",
      "Epoch 9/80\n",
      "930/930 [==============================] - 642s - loss: 0.9724 - categorical_accuracy: 0.9670 - val_loss: 1.3957 - val_categorical_accuracy: 0.8222\n",
      "Epoch 10/80\n",
      "930/930 [==============================] - 642s - loss: 0.6941 - categorical_accuracy: 0.9714 - val_loss: 1.2197 - val_categorical_accuracy: 0.8369\n",
      "Epoch 11/80\n",
      "930/930 [==============================] - 642s - loss: 0.5085 - categorical_accuracy: 0.9781 - val_loss: 1.0182 - val_categorical_accuracy: 0.8366\n",
      "Epoch 12/80\n",
      "930/930 [==============================] - 642s - loss: 0.3800 - categorical_accuracy: 0.9829 - val_loss: 1.0303 - val_categorical_accuracy: 0.8304\n",
      "Epoch 13/80\n",
      "930/930 [==============================] - 642s - loss: 0.2992 - categorical_accuracy: 0.9835 - val_loss: 0.9138 - val_categorical_accuracy: 0.8222\n",
      "Epoch 14/80\n",
      "930/930 [==============================] - 642s - loss: 0.2387 - categorical_accuracy: 0.9865 - val_loss: 0.9368 - val_categorical_accuracy: 0.8276\n",
      "Epoch 15/80\n",
      "930/930 [==============================] - 642s - loss: 0.1983 - categorical_accuracy: 0.9883 - val_loss: 0.9273 - val_categorical_accuracy: 0.8268\n",
      "Epoch 16/80\n",
      "930/930 [==============================] - 642s - loss: 0.1656 - categorical_accuracy: 0.9900 - val_loss: 0.9513 - val_categorical_accuracy: 0.8184\n",
      "Epoch 17/80\n",
      "930/930 [==============================] - 642s - loss: 0.1462 - categorical_accuracy: 0.9900 - val_loss: 1.0259 - val_categorical_accuracy: 0.8117\n",
      "Epoch 18/80\n",
      "929/930 [============================>.] - ETA: 0s - loss: 0.1294 - categorical_accuracy: 0.9910\n",
      "Epoch 00017: reducing learning rate to 2.9999999242136253e-06.\n",
      "930/930 [==============================] - 642s - loss: 0.1293 - categorical_accuracy: 0.9910 - val_loss: 0.9796 - val_categorical_accuracy: 0.8230\n",
      "Epoch 19/80\n",
      "930/930 [==============================] - 642s - loss: 0.0931 - categorical_accuracy: 0.9994 - val_loss: 1.0590 - val_categorical_accuracy: 0.8297\n",
      "Epoch 20/80\n",
      "930/930 [==============================] - 641s - loss: 0.0779 - categorical_accuracy: 0.9999 - val_loss: 1.0612 - val_categorical_accuracy: 0.8304\n",
      "Epoch 21/80\n",
      "930/930 [==============================] - 642s - loss: 0.0664 - categorical_accuracy: 0.9994 - val_loss: 0.9543 - val_categorical_accuracy: 0.8308\n",
      "Epoch 22/80\n",
      "929/930 [============================>.] - ETA: 0s - loss: 0.0595 - categorical_accuracy: 0.9990\n",
      "Epoch 00021: reducing learning rate to 1e-06.\n",
      "930/930 [==============================] - 642s - loss: 0.0595 - categorical_accuracy: 0.9990 - val_loss: 0.9778 - val_categorical_accuracy: 0.8335\n",
      "Epoch 23/80\n",
      "930/930 [==============================] - 642s - loss: 0.0503 - categorical_accuracy: 1.0000 - val_loss: 1.0449 - val_categorical_accuracy: 0.8346\n",
      "Epoch 24/80\n",
      "930/930 [==============================] - 641s - loss: 0.0461 - categorical_accuracy: 1.0000 - val_loss: 0.9915 - val_categorical_accuracy: 0.8327\n",
      "Epoch 25/80\n",
      "930/930 [==============================] - 641s - loss: 0.0423 - categorical_accuracy: 0.9999 - val_loss: 1.0192 - val_categorical_accuracy: 0.8306\n",
      "Epoch 26/80\n",
      "930/930 [==============================] - 641s - loss: 0.0381 - categorical_accuracy: 1.0000 - val_loss: 1.0307 - val_categorical_accuracy: 0.8308\n",
      "Epoch 27/80\n",
      "930/930 [==============================] - 641s - loss: 0.0349 - categorical_accuracy: 0.9999 - val_loss: 1.0754 - val_categorical_accuracy: 0.8184\n",
      "Epoch 28/80\n",
      "930/930 [==============================] - 642s - loss: 0.0321 - categorical_accuracy: 0.9999 - val_loss: 0.9826 - val_categorical_accuracy: 0.8360\n",
      "Epoch 29/80\n",
      "930/930 [==============================] - 642s - loss: 0.0295 - categorical_accuracy: 1.0000 - val_loss: 1.0969 - val_categorical_accuracy: 0.8247\n",
      "Epoch 30/80\n",
      "930/930 [==============================] - 642s - loss: 0.0276 - categorical_accuracy: 0.9998 - val_loss: 1.0369 - val_categorical_accuracy: 0.8346\n",
      "Epoch 31/80\n",
      "930/930 [==============================] - 642s - loss: 0.0256 - categorical_accuracy: 1.0000 - val_loss: 1.0856 - val_categorical_accuracy: 0.8232\n",
      "Epoch 32/80\n",
      "930/930 [==============================] - 641s - loss: 0.0239 - categorical_accuracy: 1.0000 - val_loss: 1.1220 - val_categorical_accuracy: 0.8073\n",
      "Epoch 33/80\n",
      "930/930 [==============================] - 642s - loss: 0.0226 - categorical_accuracy: 1.0000 - val_loss: 1.0779 - val_categorical_accuracy: 0.8341\n",
      "Epoch 34/80\n",
      "930/930 [==============================] - 642s - loss: 0.0217 - categorical_accuracy: 0.9998 - val_loss: 1.0487 - val_categorical_accuracy: 0.8291\n",
      "Epoch 35/80\n",
      "930/930 [==============================] - 641s - loss: 0.0205 - categorical_accuracy: 0.9999 - val_loss: 1.0256 - val_categorical_accuracy: 0.8318\n",
      "Epoch 36/80\n",
      "930/930 [==============================] - 640s - loss: 0.0198 - categorical_accuracy: 0.9999 - val_loss: 1.0302 - val_categorical_accuracy: 0.8186\n",
      "Epoch 37/80\n",
      "930/930 [==============================] - 641s - loss: 0.0183 - categorical_accuracy: 1.0000 - val_loss: 1.0622 - val_categorical_accuracy: 0.8293\n",
      "Epoch 38/80\n",
      "930/930 [==============================] - 641s - loss: 0.0181 - categorical_accuracy: 0.9999 - val_loss: 1.0126 - val_categorical_accuracy: 0.8373\n",
      "Epoch 39/80\n",
      "930/930 [==============================] - 641s - loss: 0.0176 - categorical_accuracy: 0.9998 - val_loss: 1.0011 - val_categorical_accuracy: 0.8266\n",
      "Epoch 40/80\n",
      "930/930 [==============================] - 641s - loss: 0.0164 - categorical_accuracy: 1.0000 - val_loss: 1.0964 - val_categorical_accuracy: 0.8293\n",
      "Epoch 41/80\n",
      "930/930 [==============================] - 640s - loss: 0.0158 - categorical_accuracy: 0.9999 - val_loss: 1.0059 - val_categorical_accuracy: 0.8358\n",
      "Epoch 42/80\n",
      "930/930 [==============================] - 641s - loss: 0.0152 - categorical_accuracy: 0.9999 - val_loss: 1.1355 - val_categorical_accuracy: 0.8268\n",
      "Epoch 43/80\n",
      "930/930 [==============================] - 640s - loss: 0.0147 - categorical_accuracy: 1.0000 - val_loss: 1.1631 - val_categorical_accuracy: 0.8170\n",
      "Epoch 44/80\n",
      "930/930 [==============================] - 645s - loss: 0.0148 - categorical_accuracy: 0.9998 - val_loss: 1.0532 - val_categorical_accuracy: 0.8295\n",
      "Epoch 45/80\n",
      "930/930 [==============================] - 640s - loss: 0.0134 - categorical_accuracy: 1.0000 - val_loss: 1.1393 - val_categorical_accuracy: 0.8281\n",
      "Epoch 46/80\n",
      "930/930 [==============================] - 641s - loss: 0.0140 - categorical_accuracy: 0.9999 - val_loss: 1.1250 - val_categorical_accuracy: 0.8224\n",
      "Epoch 47/80\n",
      "930/930 [==============================] - 640s - loss: 0.0131 - categorical_accuracy: 0.9999 - val_loss: 1.0437 - val_categorical_accuracy: 0.8245\n",
      "Epoch 48/80\n",
      "930/930 [==============================] - 641s - loss: 0.0124 - categorical_accuracy: 1.0000 - val_loss: 1.1409 - val_categorical_accuracy: 0.8222\n",
      "Epoch 49/80\n",
      "930/930 [==============================] - 641s - loss: 0.0129 - categorical_accuracy: 0.9999 - val_loss: 1.0604 - val_categorical_accuracy: 0.8302\n",
      "Epoch 50/80\n",
      "930/930 [==============================] - 635s - loss: 0.0116 - categorical_accuracy: 1.0000 - val_loss: 1.1475 - val_categorical_accuracy: 0.8220\n",
      "Epoch 51/80\n",
      "930/930 [==============================] - 635s - loss: 0.0116 - categorical_accuracy: 0.9999 - val_loss: 1.1232 - val_categorical_accuracy: 0.8222\n",
      "Epoch 52/80\n",
      "930/930 [==============================] - 634s - loss: 0.0112 - categorical_accuracy: 1.0000 - val_loss: 1.1391 - val_categorical_accuracy: 0.8235\n",
      "Epoch 53/80\n",
      "930/930 [==============================] - 635s - loss: 0.0115 - categorical_accuracy: 0.9998 - val_loss: 1.1302 - val_categorical_accuracy: 0.8339\n",
      "Epoch 54/80\n",
      "930/930 [==============================] - 635s - loss: 0.0112 - categorical_accuracy: 0.9999 - val_loss: 1.1368 - val_categorical_accuracy: 0.8241\n",
      "Epoch 55/80\n",
      "930/930 [==============================] - 634s - loss: 0.0102 - categorical_accuracy: 1.0000 - val_loss: 1.1203 - val_categorical_accuracy: 0.8253\n",
      "Epoch 56/80\n",
      "930/930 [==============================] - 634s - loss: 0.0098 - categorical_accuracy: 1.0000 - val_loss: 1.1172 - val_categorical_accuracy: 0.8366\n",
      "Epoch 57/80\n",
      "930/930 [==============================] - 635s - loss: 0.0112 - categorical_accuracy: 0.9996 - val_loss: 1.1853 - val_categorical_accuracy: 0.8255\n",
      "Epoch 58/80\n",
      "930/930 [==============================] - 634s - loss: 0.0096 - categorical_accuracy: 1.0000 - val_loss: 1.1382 - val_categorical_accuracy: 0.8218\n",
      "Epoch 59/80\n",
      "930/930 [==============================] - 634s - loss: 0.0093 - categorical_accuracy: 1.0000 - val_loss: 1.1223 - val_categorical_accuracy: 0.8293\n",
      "Epoch 60/80\n",
      "930/930 [==============================] - 635s - loss: 0.0097 - categorical_accuracy: 1.0000 - val_loss: 1.1919 - val_categorical_accuracy: 0.8276\n",
      "Epoch 61/80\n",
      "930/930 [==============================] - 634s - loss: 0.0091 - categorical_accuracy: 0.9999 - val_loss: 1.0120 - val_categorical_accuracy: 0.8249\n",
      "Epoch 62/80\n",
      "930/930 [==============================] - 635s - loss: 0.0093 - categorical_accuracy: 0.9999 - val_loss: 1.1432 - val_categorical_accuracy: 0.8182\n",
      "Epoch 63/80\n",
      "930/930 [==============================] - 634s - loss: 0.0084 - categorical_accuracy: 1.0000 - val_loss: 1.1613 - val_categorical_accuracy: 0.8260\n",
      "Epoch 64/80\n",
      "930/930 [==============================] - 635s - loss: 0.0096 - categorical_accuracy: 0.9996 - val_loss: 1.1608 - val_categorical_accuracy: 0.8306\n",
      "Epoch 65/80\n",
      "930/930 [==============================] - 634s - loss: 0.0083 - categorical_accuracy: 1.0000 - val_loss: 1.1911 - val_categorical_accuracy: 0.8218\n",
      "Epoch 66/80\n",
      "930/930 [==============================] - 635s - loss: 0.0092 - categorical_accuracy: 0.9997 - val_loss: 1.1198 - val_categorical_accuracy: 0.8247\n",
      "Epoch 67/80\n",
      "930/930 [==============================] - 634s - loss: 0.0082 - categorical_accuracy: 0.9999 - val_loss: 1.0648 - val_categorical_accuracy: 0.8285\n",
      "Epoch 68/80\n",
      "930/930 [==============================] - 635s - loss: 0.0088 - categorical_accuracy: 0.9998 - val_loss: 1.1244 - val_categorical_accuracy: 0.8245\n",
      "Epoch 69/80\n",
      "930/930 [==============================] - 634s - loss: 0.0078 - categorical_accuracy: 1.0000 - val_loss: 1.1614 - val_categorical_accuracy: 0.8281\n",
      "Epoch 70/80\n",
      "930/930 [==============================] - 635s - loss: 0.0083 - categorical_accuracy: 0.9999 - val_loss: 1.2306 - val_categorical_accuracy: 0.8214\n",
      "Epoch 71/80\n",
      "930/930 [==============================] - 634s - loss: 0.0086 - categorical_accuracy: 0.9996 - val_loss: 1.0276 - val_categorical_accuracy: 0.8266\n",
      "Epoch 72/80\n",
      "930/930 [==============================] - 635s - loss: 0.0077 - categorical_accuracy: 1.0000 - val_loss: 1.1453 - val_categorical_accuracy: 0.8270\n",
      "Epoch 73/80\n",
      "930/930 [==============================] - 634s - loss: 0.0073 - categorical_accuracy: 1.0000 - val_loss: 1.1945 - val_categorical_accuracy: 0.8272\n",
      "Epoch 74/80\n",
      "930/930 [==============================] - 635s - loss: 0.0083 - categorical_accuracy: 0.9998 - val_loss: 1.1971 - val_categorical_accuracy: 0.8170\n",
      "Epoch 75/80\n",
      "930/930 [==============================] - 634s - loss: 0.0073 - categorical_accuracy: 0.9999 - val_loss: 1.1350 - val_categorical_accuracy: 0.8253\n",
      "Epoch 76/80\n",
      "930/930 [==============================] - 635s - loss: 0.0084 - categorical_accuracy: 0.9997 - val_loss: 1.1061 - val_categorical_accuracy: 0.8272\n",
      "Epoch 77/80\n",
      "930/930 [==============================] - 634s - loss: 0.0069 - categorical_accuracy: 1.0000 - val_loss: 1.2522 - val_categorical_accuracy: 0.8117\n",
      "Epoch 78/80\n",
      "930/930 [==============================] - 634s - loss: 0.0066 - categorical_accuracy: 1.0000 - val_loss: 1.1634 - val_categorical_accuracy: 0.8323\n",
      "Epoch 79/80\n",
      "930/930 [==============================] - 635s - loss: 0.0078 - categorical_accuracy: 0.9998 - val_loss: 1.1686 - val_categorical_accuracy: 0.8115\n",
      "Epoch 80/80\n",
      "930/930 [==============================] - 635s - loss: 0.0072 - categorical_accuracy: 0.9999 - val_loss: 1.1585 - val_categorical_accuracy: 0.8237\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "# Change Save paths before running !!\n",
    "now = datetime.now()\n",
    "if training_mode == 'source': # Training on source data from physionet\n",
    "    csv_logger = CSVLogger('/media/jaskmo/ELEK/bme/Project02456/trainingLog/sourceModel' + \n",
    "                           str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                           str(now.hour) + str(now.minute) + '.log')\n",
    "    # Train the model\n",
    "    # fit_generator(train_generator, steps_per_epoch=trainStepEpoch, validation_data=validation_generator,\n",
    "    #                  validation_steps=valStepEpoch, epochs=50, verbose=1, callbacks=[csv_logger, reduce_lr])\n",
    "\n",
    "    vggConvSleep.fit_generator(train_generator, steps_per_epoch=trainStepEpoch, validation_data=validation_generator, \n",
    "                               validation_steps=valStepEpoch, epochs=80, verbose=1, callbacks=[reduce_lr, csv_logger], \n",
    "                              )#class_weight=weights_dic)\n",
    "    \n",
    "    # save model\n",
    "    vggConvSleep.save(filepath='/home/jaskmo/Documents/programering/02456DomainAdaptation/models/kerasSource' + \n",
    "                  str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                  str(now.hour) + str(now.minute) + '.h5')\n",
    "\n",
    "elif training_mode == 'target': # Training on target data from hospital\n",
    "    csv_logger = CSVLogger('/media/jaskmo/ELEK/bme/Project02456/trainingLog/targetModel' + \n",
    "                           str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                           str(now.hour) + str(now.minute) + '.log')\n",
    "    # Train the model\n",
    "    vggConvSleep.fit_generator(train_generator, steps_per_epoch=trainStepEpoch, validation_data=validation_generator,\n",
    "                               validation_steps=valStepEpoch, epochs=80, verbose=1, callbacks=[reduce_lr, csv_logger],\n",
    "                              )#class_weight=weights_dic)\n",
    "    \n",
    "    # save model\n",
    "    vggConvSleep.save(filepath='/home/jaskmo/Documents/programering/02456DomainAdaptation/models/kerasTarget' + \n",
    "                  str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                  str(now.hour) + str(now.minute) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on both source and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img, test_lable = test_generator.next()\n",
    "for count in range(int(np.floor(testStepEpoch))):\n",
    "    tmp_img, tmp_lable = test_generator.next()\n",
    "    test_img = np.concatenate((test_img, tmp_img), axis=0)\n",
    "    test_lable = np.concatenate((test_lable, tmp_lable),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in this domain =  0.803469704816\n",
      "[[ 118   53    0   20   20]\n",
      " [ 155 1484  111   98    9]\n",
      " [   8   52  441    7    1]\n",
      " [  42  118    0  688    3]\n",
      " [  36   14    0   12  372]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         N1       0.33      0.56      0.41       211\n",
      "         N2       0.86      0.80      0.83      1857\n",
      "         N3       0.80      0.87      0.83       509\n",
      "        REM       0.83      0.81      0.82       851\n",
      "       wake       0.92      0.86      0.89       434\n",
      "\n",
      "avg / total       0.82      0.80      0.81      3862\n",
      "\n",
      "Accuracy on other domain =  0.829411764706\n"
     ]
    }
   ],
   "source": [
    "#loss, metric = vggConvSleep.evaluate(x=inputs_test_phys, y=targets_test_phys, batch_size=50)\n",
    "inv_map = {v: k for k, v in test_generator.class_indices.items()}\n",
    "target_names = list(inv_map.values())\n",
    "\n",
    "targets_test_int = [np.where(r == 1)[0][0] for r in test_lable]\n",
    "y_pred = vggConvSleep.predict(test_img)\n",
    "y_pred2 = np.argmax(y_pred, axis = 1)\n",
    "# Test accuracy:\n",
    "acc = accuracy_score(targets_test_int, y_pred2)\n",
    "print('Accuracy in this domain = ', acc)\n",
    "\n",
    "conf_mat = confusion_matrix(targets_test_int, y_pred2)\n",
    "print(conf_mat)\n",
    "# Per class metrics\n",
    "class_report = classification_report(targets_test_int, y_pred2, target_names=target_names)\n",
    "print(class_report)\n",
    "\n",
    "# Evaluate error on target data\n",
    "_, metric = vggConvSleep.evaluate_generator(OC_test_generator, steps=OC_testStepEpoch)\n",
    "print('Accuracy on other domain = ', metric)\n",
    "\n",
    "    \n",
    "# elif training_mode == 'target': # Training on target data from hospital\n",
    "#     # Convert from onehot\n",
    "#     targets_test_int = [np.where(r == 1)[0][0] for r in targets_test_hosp]\n",
    "#     y_pred = vggConvSleep.predict(inputs_test_hosp)\n",
    "#     y_pred2 = np.argmax(y_pred, axis = 1)\n",
    "#     # Test accuracy:\n",
    "#     acc = accuracy_score(targets_test_int, y_pred2)\n",
    "#     print('Accuracy in this domain = ', acc)\n",
    "#     # Confusion matrix for target\n",
    "#     conf_mat = confusion_matrix(targets_test_int, y_pred2)\n",
    "#     print(conf_mat)\n",
    "#     # Per class metrics\n",
    "#     class_report = classification_report(targets_test_int, y_pred2, target_names=target_names)\n",
    "#     print(class_report)\n",
    "    \n",
    "#     # Evaluate error on source data\n",
    "#     _, metric = vggConvSleep.evaluate(x=inputs_test_phys, y=targets_test_phys, batch_size=50)\n",
    "#     print('Accuracy on other domain = ', metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reverse_data_split(path + 'taperImages/pysNetData/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create_data_split(path + 'taperImages/pysNetData/','pys', 2, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
