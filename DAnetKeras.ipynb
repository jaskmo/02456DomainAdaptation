{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, Callback\n",
    "from datetime import datetime\n",
    "import keras.backend as K\n",
    "import extras.ourUtils as utils\n",
    "import numpy as np\n",
    "import Models\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from extras.ourUtils import reverse_data_split, create_data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nrEpochs = 10\n",
    "full_train = True\n",
    "path = '/home/jaskmo/Documents/programering/02456DomainAdaptation/'\n",
    "source_data = path + 'newTaperImg/Physionet/'\n",
    "target_data = path + 'newTaperImg/Hospital/'\n",
    "stdout_cell = sys.stdout\n",
    "MIQ = ['DA', 'target', 'source']\n",
    "kf = KFold(n_splits = 10)\n",
    "n_subjects_phys = np.arange(1,21);\n",
    "n_subjects_hosp = np.arange(1,35);\n",
    "\n",
    "class FlipControle(Callback):\n",
    "    def __init__(self, alphaIn):\n",
    "        self.alpha = alphaIn\n",
    "        print(K.get_value(lamFunk))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        p = (epoch+1)/nrEpochs\n",
    "        K.set_value(self.alpha, (2/(1+np.exp(-10*p)))-1)\n",
    "        print(K.get_value(lamFunk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data as generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# make a data generator for dplInput\n",
    "def train_gen_DAnet(source, target, batch_size):\n",
    "    half = batch_size//2\n",
    "    while True:\n",
    "        source_data, source_lable = source.next()\n",
    "        target_data, target_lable = target.next()\n",
    "        if len(source_lable) != batch_size or len(target_lable) != batch_size:\n",
    "            continue\n",
    "        dpl_data = np.concatenate((source_data[:half,...],target_data[:half,...]),axis=0)\n",
    "               \n",
    "        domain_tmp = np.ones(batch_size, dtype='int8')\n",
    "        domain_tmp[half:] = domain_tmp[half:] * 0\n",
    "        dpl_lable = np.concatenate((domain_tmp.reshape(batch_size,1),\n",
    "                                       np.flip(domain_tmp,0).reshape(batch_size,1)),1)\n",
    "\n",
    "        yield({'lplInput':source_data,'dplInput':dpl_data}, {'lplOut':source_lable,'dplOut':dpl_lable})\n",
    "        \n",
    "def test_gen_DAnet(source, target, batch_size):\n",
    "    half = batch_size//2\n",
    "    while True:\n",
    "        source_data, source_lable = source.next()\n",
    "        target_data, target_lable = target.next()\n",
    "        if len(source_lable) != batch_size or len(target_lable) != batch_size:\n",
    "            continue\n",
    "        dpl_data = np.concatenate((source_data[:half,...],target_data[:half,...]),axis=0)\n",
    "               \n",
    "        domain_tmp = np.ones(batch_size, dtype='int8')\n",
    "        domain_tmp[half:] = domain_tmp[half:] * 0\n",
    "        dpl_lable = np.concatenate((domain_tmp.reshape(batch_size,1),\n",
    "                                       np.flip(domain_tmp,0).reshape(batch_size,1)),1)\n",
    "\n",
    "        yield({'lplInput':target_data,'dplInput':dpl_data}, {'lplOut':target_lable,'dplOut':dpl_lable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whitelist = dir()\n",
    "whitelist.append('whitelist')\n",
    "whitelist.append('phys_split')\n",
    "whitelist.append('hosp_split')\n",
    "whitelist.append('this')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23124 images belonging to 5 classes.\n",
      "Found 17038 images belonging to 5 classes.\n",
      "Found 2414 images belonging to 5 classes.\n",
      "Found 3118 images belonging to 5 classes.\n",
      "Found 2816 images belonging to 5 classes.\n",
      "Found 2793 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n",
      "Epoch 1/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 20.9197 - lplOut_loss: 1.1027 - dplOut_loss: 0.2665 - lplOut_categorical_accuracy: 0.5615 - dplOut_categorical_accuracy: 0.90880.462117\n",
      "361/361 [==============================] - 264s - loss: 20.9102 - lplOut_loss: 1.1019 - dplOut_loss: 0.2663 - lplOut_categorical_accuracy: 0.5619 - dplOut_categorical_accuracy: 0.9088 - val_loss: 18.8875 - val_lplOut_loss: 2.3201 - val_dplOut_loss: 0.1319 - val_lplOut_categorical_accuracy: 0.3209 - val_dplOut_categorical_accuracy: 0.9514\n",
      "Epoch 2/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 15.2549 - lplOut_loss: 0.6905 - dplOut_loss: 0.1283 - lplOut_categorical_accuracy: 0.7447 - dplOut_categorical_accuracy: 0.95470.761594\n",
      "361/361 [==============================] - 263s - loss: 15.2503 - lplOut_loss: 0.6905 - dplOut_loss: 0.1284 - lplOut_categorical_accuracy: 0.7447 - dplOut_categorical_accuracy: 0.9547 - val_loss: 15.4633 - val_lplOut_loss: 2.5441 - val_dplOut_loss: 0.1630 - val_lplOut_categorical_accuracy: 0.3252 - val_dplOut_categorical_accuracy: 0.9257\n",
      "Epoch 3/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 12.2971 - lplOut_loss: 0.6118 - dplOut_loss: 0.1212 - lplOut_categorical_accuracy: 0.7727 - dplOut_categorical_accuracy: 0.95920.905148\n",
      "361/361 [==============================] - 264s - loss: 12.2945 - lplOut_loss: 0.6121 - dplOut_loss: 0.1212 - lplOut_categorical_accuracy: 0.7726 - dplOut_categorical_accuracy: 0.9592 - val_loss: 13.2501 - val_lplOut_loss: 2.5823 - val_dplOut_loss: 0.1407 - val_lplOut_categorical_accuracy: 0.3269 - val_dplOut_categorical_accuracy: 0.9459\n",
      "Epoch 4/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 10.4974 - lplOut_loss: 0.5764 - dplOut_loss: 0.1720 - lplOut_categorical_accuracy: 0.7832 - dplOut_categorical_accuracy: 0.93910.964028\n",
      "361/361 [==============================] - 264s - loss: 10.4956 - lplOut_loss: 0.5765 - dplOut_loss: 0.1720 - lplOut_categorical_accuracy: 0.7831 - dplOut_categorical_accuracy: 0.9391 - val_loss: 11.9747 - val_lplOut_loss: 2.6975 - val_dplOut_loss: 0.2207 - val_lplOut_categorical_accuracy: 0.3066 - val_dplOut_categorical_accuracy: 0.9134\n",
      "Epoch 5/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 9.2880 - lplOut_loss: 0.5564 - dplOut_loss: 0.2230 - lplOut_categorical_accuracy: 0.7943 - dplOut_categorical_accuracy: 0.91720.986614\n",
      "361/361 [==============================] - 264s - loss: 9.2865 - lplOut_loss: 0.5564 - dplOut_loss: 0.2229 - lplOut_categorical_accuracy: 0.7944 - dplOut_categorical_accuracy: 0.9173 - val_loss: 10.8904 - val_lplOut_loss: 2.6814 - val_dplOut_loss: 0.2048 - val_lplOut_categorical_accuracy: 0.3100 - val_dplOut_categorical_accuracy: 0.9253\n",
      "Epoch 6/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 8.3478 - lplOut_loss: 0.5408 - dplOut_loss: 0.2303 - lplOut_categorical_accuracy: 0.7997 - dplOut_categorical_accuracy: 0.91950.995055\n",
      "361/361 [==============================] - 265s - loss: 8.3470 - lplOut_loss: 0.5409 - dplOut_loss: 0.2305 - lplOut_categorical_accuracy: 0.7996 - dplOut_categorical_accuracy: 0.9194 - val_loss: 10.1938 - val_lplOut_loss: 2.7218 - val_dplOut_loss: 0.2998 - val_lplOut_categorical_accuracy: 0.3222 - val_dplOut_categorical_accuracy: 0.8902\n",
      "Epoch 7/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 7.6136 - lplOut_loss: 0.5314 - dplOut_loss: 0.2681 - lplOut_categorical_accuracy: 0.8040 - dplOut_categorical_accuracy: 0.90690.998178\n",
      "361/361 [==============================] - 263s - loss: 7.6125 - lplOut_loss: 0.5311 - dplOut_loss: 0.2682 - lplOut_categorical_accuracy: 0.8041 - dplOut_categorical_accuracy: 0.9068 - val_loss: 9.6033 - val_lplOut_loss: 2.7744 - val_dplOut_loss: 0.3605 - val_lplOut_categorical_accuracy: 0.3226 - val_dplOut_categorical_accuracy: 0.8674\n",
      "Epoch 8/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 7.0164 - lplOut_loss: 0.5290 - dplOut_loss: 0.3332 - lplOut_categorical_accuracy: 0.8055 - dplOut_categorical_accuracy: 0.88110.999329\n",
      "361/361 [==============================] - 264s - loss: 7.0154 - lplOut_loss: 0.5290 - dplOut_loss: 0.3331 - lplOut_categorical_accuracy: 0.8055 - dplOut_categorical_accuracy: 0.8812 - val_loss: 8.8803 - val_lplOut_loss: 2.5876 - val_dplOut_loss: 0.4433 - val_lplOut_categorical_accuracy: 0.3260 - val_dplOut_categorical_accuracy: 0.8505\n",
      "Epoch 9/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 6.4767 - lplOut_loss: 0.5281 - dplOut_loss: 0.3803 - lplOut_categorical_accuracy: 0.8045 - dplOut_categorical_accuracy: 0.86210.999753\n",
      "361/361 [==============================] - 264s - loss: 6.4757 - lplOut_loss: 0.5279 - dplOut_loss: 0.3803 - lplOut_categorical_accuracy: 0.8045 - dplOut_categorical_accuracy: 0.8621 - val_loss: 8.4475 - val_lplOut_loss: 2.6837 - val_dplOut_loss: 0.4721 - val_lplOut_categorical_accuracy: 0.3243 - val_dplOut_categorical_accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "360/361 [============================>.] - ETA: 0s - loss: 5.9999 - lplOut_loss: 0.5296 - dplOut_loss: 0.4369 - lplOut_categorical_accuracy: 0.8049 - dplOut_categorical_accuracy: 0.82750.999909\n",
      "361/361 [==============================] - 262s - loss: 5.9994 - lplOut_loss: 0.5297 - dplOut_loss: 0.4370 - lplOut_categorical_accuracy: 0.8049 - dplOut_categorical_accuracy: 0.8274 - val_loss: 8.0786 - val_lplOut_loss: 2.7391 - val_dplOut_loss: 0.5599 - val_lplOut_categorical_accuracy: 0.3091 - val_dplOut_categorical_accuracy: 0.7559\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "266/266 [==============================] - 105s - loss: 12.0870 - categorical_accuracy: 0.2541 - val_loss: 10.8763 - val_categorical_accuracy: 0.2767\n",
      "Epoch 2/10\n",
      "266/266 [==============================] - 102s - loss: 10.0806 - categorical_accuracy: 0.2884 - val_loss: 9.2673 - val_categorical_accuracy: 0.3124\n",
      "Epoch 3/10\n",
      "266/266 [==============================] - 102s - loss: 8.7098 - categorical_accuracy: 0.3046 - val_loss: 8.1211 - val_categorical_accuracy: 0.3245\n",
      "Epoch 4/10\n",
      "266/266 [==============================] - 102s - loss: 7.7148 - categorical_accuracy: 0.3179 - val_loss: 7.2956 - val_categorical_accuracy: 0.3219\n",
      "Epoch 5/10\n",
      "266/266 [==============================] - 103s - loss: 6.9904 - categorical_accuracy: 0.3210 - val_loss: 6.6788 - val_categorical_accuracy: 0.3186\n",
      "Epoch 6/10\n",
      "266/266 [==============================] - 103s - loss: 6.4282 - categorical_accuracy: 0.3356 - val_loss: 6.1887 - val_categorical_accuracy: 0.3157\n",
      "Epoch 7/10\n",
      "266/266 [==============================] - 103s - loss: 5.9765 - categorical_accuracy: 0.3417 - val_loss: 5.7898 - val_categorical_accuracy: 0.3173\n",
      "Epoch 8/10\n",
      "266/266 [==============================] - 103s - loss: 5.5972 - categorical_accuracy: 0.3565 - val_loss: 5.4508 - val_categorical_accuracy: 0.3242\n",
      "Epoch 9/10\n",
      "266/266 [==============================] - 103s - loss: 5.2788 - categorical_accuracy: 0.3620 - val_loss: 5.1757 - val_categorical_accuracy: 0.2911\n",
      "Epoch 10/10\n",
      "266/266 [==============================] - 102s - loss: 4.9916 - categorical_accuracy: 0.3736 - val_loss: 4.9343 - val_categorical_accuracy: 0.3088\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "361/361 [==============================] - 132s - loss: 11.1575 - categorical_accuracy: 0.5663 - val_loss: 9.2310 - val_categorical_accuracy: 0.8128\n",
      "Epoch 2/10\n",
      "361/361 [==============================] - 131s - loss: 8.5902 - categorical_accuracy: 0.7453 - val_loss: 7.6081 - val_categorical_accuracy: 0.8481\n",
      "Epoch 3/10\n",
      "361/361 [==============================] - 131s - loss: 7.2969 - categorical_accuracy: 0.7732 - val_loss: 6.6142 - val_categorical_accuracy: 0.8553\n",
      "Epoch 4/10\n",
      "361/361 [==============================] - 131s - loss: 6.4516 - categorical_accuracy: 0.7880 - val_loss: 5.9185 - val_categorical_accuracy: 0.8655\n",
      "Epoch 5/10\n",
      "361/361 [==============================] - 131s - loss: 5.8388 - categorical_accuracy: 0.7993 - val_loss: 5.4110 - val_categorical_accuracy: 0.8672\n",
      "Epoch 6/10\n",
      "361/361 [==============================] - 131s - loss: 5.3476 - categorical_accuracy: 0.8107 - val_loss: 4.9747 - val_categorical_accuracy: 0.8638\n",
      "Epoch 7/10\n",
      "361/361 [==============================] - 131s - loss: 4.9302 - categorical_accuracy: 0.8152 - val_loss: 4.6028 - val_categorical_accuracy: 0.8638\n",
      "Epoch 8/10\n",
      "361/361 [==============================] - 131s - loss: 4.5650 - categorical_accuracy: 0.8221 - val_loss: 4.2851 - val_categorical_accuracy: 0.8596\n",
      "Epoch 9/10\n",
      "361/361 [==============================] - 131s - loss: 4.2379 - categorical_accuracy: 0.8287 - val_loss: 3.9560 - val_categorical_accuracy: 0.8787\n",
      "Epoch 10/10\n",
      "361/361 [==============================] - 131s - loss: 3.9367 - categorical_accuracy: 0.8325 - val_loss: 3.7008 - val_categorical_accuracy: 0.8702\n",
      "Found 23862 images belonging to 5 classes.\n",
      "Found 16554 images belonging to 5 classes.\n",
      "Found 1971 images belonging to 5 classes.\n",
      "Found 3128 images belonging to 5 classes.\n",
      "Found 2489 images belonging to 5 classes.\n",
      "Found 3319 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 20.9176 - lplOut_loss: 1.0869 - dplOut_loss: 0.2824 - lplOut_categorical_accuracy: 0.5712 - dplOut_categorical_accuracy: 0.89660.462117\n",
      "372/372 [==============================] - 266s - loss: 20.9079 - lplOut_loss: 1.0860 - dplOut_loss: 0.2820 - lplOut_categorical_accuracy: 0.5717 - dplOut_categorical_accuracy: 0.8968 - val_loss: 18.8157 - val_lplOut_loss: 2.2584 - val_dplOut_loss: 0.1210 - val_lplOut_categorical_accuracy: 0.3625 - val_dplOut_categorical_accuracy: 0.9521\n",
      "Epoch 2/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 15.2450 - lplOut_loss: 0.6583 - dplOut_loss: 0.1337 - lplOut_categorical_accuracy: 0.7584 - dplOut_categorical_accuracy: 0.95370.761594\n",
      "372/372 [==============================] - 265s - loss: 15.2402 - lplOut_loss: 0.6581 - dplOut_loss: 0.1336 - lplOut_categorical_accuracy: 0.7586 - dplOut_categorical_accuracy: 0.9537 - val_loss: 15.4804 - val_lplOut_loss: 2.5770 - val_dplOut_loss: 0.1142 - val_lplOut_categorical_accuracy: 0.3719 - val_dplOut_categorical_accuracy: 0.9536\n",
      "Epoch 3/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 12.3329 - lplOut_loss: 0.5872 - dplOut_loss: 0.1354 - lplOut_categorical_accuracy: 0.7834 - dplOut_categorical_accuracy: 0.95570.905148\n",
      "372/372 [==============================] - 265s - loss: 12.3302 - lplOut_loss: 0.5871 - dplOut_loss: 0.1355 - lplOut_categorical_accuracy: 0.7835 - dplOut_categorical_accuracy: 0.9556 - val_loss: 13.2774 - val_lplOut_loss: 2.5516 - val_dplOut_loss: 0.1394 - val_lplOut_categorical_accuracy: 0.3729 - val_dplOut_categorical_accuracy: 0.9516\n",
      "Epoch 4/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 10.5794 - lplOut_loss: 0.5534 - dplOut_loss: 0.2062 - lplOut_categorical_accuracy: 0.7964 - dplOut_categorical_accuracy: 0.92310.964028\n",
      "372/372 [==============================] - 265s - loss: 10.5777 - lplOut_loss: 0.5536 - dplOut_loss: 0.2061 - lplOut_categorical_accuracy: 0.7963 - dplOut_categorical_accuracy: 0.9232 - val_loss: 12.0186 - val_lplOut_loss: 2.6345 - val_dplOut_loss: 0.2468 - val_lplOut_categorical_accuracy: 0.3875 - val_dplOut_categorical_accuracy: 0.8995\n",
      "Epoch 5/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 9.3884 - lplOut_loss: 0.5389 - dplOut_loss: 0.2539 - lplOut_categorical_accuracy: 0.8008 - dplOut_categorical_accuracy: 0.90410.986614\n",
      "372/372 [==============================] - 264s - loss: 9.3872 - lplOut_loss: 0.5390 - dplOut_loss: 0.2540 - lplOut_categorical_accuracy: 0.8008 - dplOut_categorical_accuracy: 0.9042 - val_loss: 10.8968 - val_lplOut_loss: 2.5623 - val_dplOut_loss: 0.2387 - val_lplOut_categorical_accuracy: 0.4036 - val_dplOut_categorical_accuracy: 0.9177\n",
      "Epoch 6/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 8.4792 - lplOut_loss: 0.5257 - dplOut_loss: 0.2822 - lplOut_categorical_accuracy: 0.8059 - dplOut_categorical_accuracy: 0.89440.995055\n",
      "372/372 [==============================] - 266s - loss: 8.4777 - lplOut_loss: 0.5254 - dplOut_loss: 0.2821 - lplOut_categorical_accuracy: 0.8060 - dplOut_categorical_accuracy: 0.8946 - val_loss: 10.1920 - val_lplOut_loss: 2.6251 - val_dplOut_loss: 0.3004 - val_lplOut_categorical_accuracy: 0.3812 - val_dplOut_categorical_accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 7.7352 - lplOut_loss: 0.5149 - dplOut_loss: 0.3176 - lplOut_categorical_accuracy: 0.8102 - dplOut_categorical_accuracy: 0.88250.998178\n",
      "372/372 [==============================] - 265s - loss: 7.7337 - lplOut_loss: 0.5143 - dplOut_loss: 0.3175 - lplOut_categorical_accuracy: 0.8105 - dplOut_categorical_accuracy: 0.8826 - val_loss: 9.5553 - val_lplOut_loss: 2.6320 - val_dplOut_loss: 0.3731 - val_lplOut_categorical_accuracy: 0.3771 - val_dplOut_categorical_accuracy: 0.8562\n",
      "Epoch 8/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 7.1171 - lplOut_loss: 0.5103 - dplOut_loss: 0.3789 - lplOut_categorical_accuracy: 0.8131 - dplOut_categorical_accuracy: 0.85410.999329\n",
      "372/372 [==============================] - 266s - loss: 7.1161 - lplOut_loss: 0.5102 - dplOut_loss: 0.3789 - lplOut_categorical_accuracy: 0.8131 - dplOut_categorical_accuracy: 0.8541 - val_loss: 9.0137 - val_lplOut_loss: 2.6529 - val_dplOut_loss: 0.4472 - val_lplOut_categorical_accuracy: 0.3807 - val_dplOut_categorical_accuracy: 0.8365\n",
      "Epoch 9/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 6.5653 - lplOut_loss: 0.5114 - dplOut_loss: 0.4316 - lplOut_categorical_accuracy: 0.8160 - dplOut_categorical_accuracy: 0.83150.999753\n",
      "372/372 [==============================] - 265s - loss: 6.5648 - lplOut_loss: 0.5114 - dplOut_loss: 0.4318 - lplOut_categorical_accuracy: 0.8160 - dplOut_categorical_accuracy: 0.8314 - val_loss: 8.4362 - val_lplOut_loss: 2.5345 - val_dplOut_loss: 0.5641 - val_lplOut_categorical_accuracy: 0.3896 - val_dplOut_categorical_accuracy: 0.7458\n",
      "Epoch 10/10\n",
      "371/372 [============================>.] - ETA: 0s - loss: 6.0576 - lplOut_loss: 0.5012 - dplOut_loss: 0.4844 - lplOut_categorical_accuracy: 0.8171 - dplOut_categorical_accuracy: 0.80130.999909\n",
      "372/372 [==============================] - 265s - loss: 6.0574 - lplOut_loss: 0.5018 - dplOut_loss: 0.4844 - lplOut_categorical_accuracy: 0.8168 - dplOut_categorical_accuracy: 0.8013 - val_loss: 7.8923 - val_lplOut_loss: 2.5787 - val_dplOut_loss: 0.5035 - val_lplOut_categorical_accuracy: 0.3620 - val_dplOut_categorical_accuracy: 0.8089\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "258/258 [==============================] - 100s - loss: 12.1171 - categorical_accuracy: 0.2528 - val_loss: 10.9412 - val_categorical_accuracy: 0.2745\n",
      "Epoch 2/10\n",
      "258/258 [==============================] - 98s - loss: 10.1300 - categorical_accuracy: 0.2758 - val_loss: 9.3304 - val_categorical_accuracy: 0.2787\n",
      "Epoch 3/10\n",
      "258/258 [==============================] - 98s - loss: 8.7535 - categorical_accuracy: 0.2927 - val_loss: 8.1592 - val_categorical_accuracy: 0.3567\n",
      "Epoch 4/10\n",
      "258/258 [==============================] - 98s - loss: 7.7709 - categorical_accuracy: 0.3046 - val_loss: 7.3299 - val_categorical_accuracy: 0.3492\n",
      "Epoch 5/10\n",
      "258/258 [==============================] - 98s - loss: 7.0343 - categorical_accuracy: 0.3239 - val_loss: 6.6816 - val_categorical_accuracy: 0.3466\n",
      "Epoch 6/10\n",
      "258/258 [==============================] - 98s - loss: 6.4855 - categorical_accuracy: 0.3311 - val_loss: 6.2293 - val_categorical_accuracy: 0.3564\n",
      "Epoch 7/10\n",
      "258/258 [==============================] - 98s - loss: 6.0392 - categorical_accuracy: 0.3430 - val_loss: 5.8416 - val_categorical_accuracy: 0.3486\n",
      "Epoch 8/10\n",
      "258/258 [==============================] - 98s - loss: 5.6722 - categorical_accuracy: 0.3477 - val_loss: 5.5300 - val_categorical_accuracy: 0.3597\n",
      "Epoch 9/10\n",
      "258/258 [==============================] - 98s - loss: 5.3528 - categorical_accuracy: 0.3613 - val_loss: 5.2620 - val_categorical_accuracy: 0.3557\n",
      "Epoch 10/10\n",
      "258/258 [==============================] - 98s - loss: 5.0785 - categorical_accuracy: 0.3696 - val_loss: 5.0137 - val_categorical_accuracy: 0.3541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "372/372 [==============================] - 132s - loss: 11.1220 - categorical_accuracy: 0.5598 - val_loss: 9.3875 - val_categorical_accuracy: 0.7216\n",
      "Epoch 2/10\n",
      "372/372 [==============================] - 129s - loss: 8.4756 - categorical_accuracy: 0.7556 - val_loss: 7.7056 - val_categorical_accuracy: 0.7609\n",
      "Epoch 3/10\n",
      "372/372 [==============================] - 129s - loss: 7.1761 - categorical_accuracy: 0.7842 - val_loss: 6.7595 - val_categorical_accuracy: 0.7567\n",
      "Epoch 4/10\n",
      "372/372 [==============================] - 129s - loss: 6.3262 - categorical_accuracy: 0.7959 - val_loss: 6.0268 - val_categorical_accuracy: 0.7619\n",
      "Epoch 5/10\n",
      "372/372 [==============================] - 129s - loss: 5.6998 - categorical_accuracy: 0.8090 - val_loss: 5.5169 - val_categorical_accuracy: 0.7703\n",
      "Epoch 6/10\n",
      "372/372 [==============================] - 130s - loss: 5.2026 - categorical_accuracy: 0.8175 - val_loss: 5.0411 - val_categorical_accuracy: 0.7855\n",
      "Epoch 7/10\n",
      "372/372 [==============================] - 129s - loss: 4.7792 - categorical_accuracy: 0.8248 - val_loss: 4.6893 - val_categorical_accuracy: 0.7708\n",
      "Epoch 8/10\n",
      "372/372 [==============================] - 129s - loss: 4.4059 - categorical_accuracy: 0.8301 - val_loss: 4.3428 - val_categorical_accuracy: 0.7892\n",
      "Epoch 9/10\n",
      "372/372 [==============================] - 129s - loss: 4.0734 - categorical_accuracy: 0.8340 - val_loss: 3.9756 - val_categorical_accuracy: 0.7960\n",
      "Epoch 10/10\n",
      "372/372 [==============================] - 129s - loss: 3.7699 - categorical_accuracy: 0.8395 - val_loss: 3.7248 - val_categorical_accuracy: 0.7939\n",
      "Found 22494 images belonging to 5 classes.\n",
      "Found 16978 images belonging to 5 classes.\n",
      "Found 2754 images belonging to 5 classes.\n",
      "Found 3253 images belonging to 5 classes.\n",
      "Found 3149 images belonging to 5 classes.\n",
      "Found 2653 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n",
      "Epoch 1/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 21.0441 - lplOut_loss: 1.1056 - dplOut_loss: 0.2621 - lplOut_categorical_accuracy: 0.5596 - dplOut_categorical_accuracy: 0.90950.462117\n",
      "351/351 [==============================] - 253s - loss: 21.0343 - lplOut_loss: 1.1049 - dplOut_loss: 0.2616 - lplOut_categorical_accuracy: 0.5600 - dplOut_categorical_accuracy: 0.9097 - val_loss: 19.0931 - val_lplOut_loss: 2.3086 - val_dplOut_loss: 0.1692 - val_lplOut_categorical_accuracy: 0.2980 - val_dplOut_categorical_accuracy: 0.9273\n",
      "Epoch 2/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 15.4297 - lplOut_loss: 0.6827 - dplOut_loss: 0.1272 - lplOut_categorical_accuracy: 0.7442 - dplOut_categorical_accuracy: 0.95590.761594\n",
      "351/351 [==============================] - 252s - loss: 15.4247 - lplOut_loss: 0.6825 - dplOut_loss: 0.1272 - lplOut_categorical_accuracy: 0.7443 - dplOut_categorical_accuracy: 0.9558 - val_loss: 15.7237 - val_lplOut_loss: 2.6258 - val_dplOut_loss: 0.1630 - val_lplOut_categorical_accuracy: 0.3001 - val_dplOut_categorical_accuracy: 0.9339\n",
      "Epoch 3/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 12.4573 - lplOut_loss: 0.6027 - dplOut_loss: 0.1175 - lplOut_categorical_accuracy: 0.7779 - dplOut_categorical_accuracy: 0.96040.905148\n",
      "351/351 [==============================] - 252s - loss: 12.4540 - lplOut_loss: 0.6025 - dplOut_loss: 0.1174 - lplOut_categorical_accuracy: 0.7780 - dplOut_categorical_accuracy: 0.9605 - val_loss: 13.5449 - val_lplOut_loss: 2.6965 - val_dplOut_loss: 0.1554 - val_lplOut_categorical_accuracy: 0.2998 - val_dplOut_categorical_accuracy: 0.9422\n",
      "Epoch 4/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 10.6246 - lplOut_loss: 0.5616 - dplOut_loss: 0.1573 - lplOut_categorical_accuracy: 0.7929 - dplOut_categorical_accuracy: 0.94430.964028\n",
      "351/351 [==============================] - 253s - loss: 10.6230 - lplOut_loss: 0.5621 - dplOut_loss: 0.1572 - lplOut_categorical_accuracy: 0.7927 - dplOut_categorical_accuracy: 0.9444 - val_loss: 12.2616 - val_lplOut_loss: 2.8005 - val_dplOut_loss: 0.2587 - val_lplOut_categorical_accuracy: 0.2922 - val_dplOut_categorical_accuracy: 0.8863\n",
      "Epoch 5/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 9.4235 - lplOut_loss: 0.5429 - dplOut_loss: 0.2290 - lplOut_categorical_accuracy: 0.8025 - dplOut_categorical_accuracy: 0.91330.986614\n",
      "351/351 [==============================] - 253s - loss: 9.4225 - lplOut_loss: 0.5433 - dplOut_loss: 0.2290 - lplOut_categorical_accuracy: 0.8024 - dplOut_categorical_accuracy: 0.9133 - val_loss: 11.2851 - val_lplOut_loss: 2.8666 - val_dplOut_loss: 0.2717 - val_lplOut_categorical_accuracy: 0.2918 - val_dplOut_categorical_accuracy: 0.8899\n",
      "Epoch 6/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 8.4896 - lplOut_loss: 0.5257 - dplOut_loss: 0.2426 - lplOut_categorical_accuracy: 0.8052 - dplOut_categorical_accuracy: 0.91150.995055\n",
      "351/351 [==============================] - 253s - loss: 8.4883 - lplOut_loss: 0.5255 - dplOut_loss: 0.2426 - lplOut_categorical_accuracy: 0.8054 - dplOut_categorical_accuracy: 0.9116 - val_loss: 10.3551 - val_lplOut_loss: 2.7142 - val_dplOut_loss: 0.3226 - val_lplOut_categorical_accuracy: 0.3198 - val_dplOut_categorical_accuracy: 0.8554\n",
      "Epoch 7/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 7.7613 - lplOut_loss: 0.5207 - dplOut_loss: 0.2778 - lplOut_categorical_accuracy: 0.8083 - dplOut_categorical_accuracy: 0.89910.998178\n",
      "351/351 [==============================] - 253s - loss: 7.7606 - lplOut_loss: 0.5207 - dplOut_loss: 0.2782 - lplOut_categorical_accuracy: 0.8083 - dplOut_categorical_accuracy: 0.8989 - val_loss: 9.6675 - val_lplOut_loss: 2.7122 - val_dplOut_loss: 0.3353 - val_lplOut_categorical_accuracy: 0.3056 - val_dplOut_categorical_accuracy: 0.8695\n",
      "Epoch 8/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 7.1571 - lplOut_loss: 0.5152 - dplOut_loss: 0.3332 - lplOut_categorical_accuracy: 0.8132 - dplOut_categorical_accuracy: 0.87590.999329\n",
      "351/351 [==============================] - 252s - loss: 7.1560 - lplOut_loss: 0.5150 - dplOut_loss: 0.3332 - lplOut_categorical_accuracy: 0.8131 - dplOut_categorical_accuracy: 0.8760 - val_loss: 9.0666 - val_lplOut_loss: 2.6995 - val_dplOut_loss: 0.3626 - val_lplOut_categorical_accuracy: 0.3041 - val_dplOut_categorical_accuracy: 0.8619\n",
      "Epoch 9/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 6.6055 - lplOut_loss: 0.5050 - dplOut_loss: 0.3775 - lplOut_categorical_accuracy: 0.8160 - dplOut_categorical_accuracy: 0.85700.999753\n",
      "351/351 [==============================] - 252s - loss: 6.6051 - lplOut_loss: 0.5053 - dplOut_loss: 0.3775 - lplOut_categorical_accuracy: 0.8159 - dplOut_categorical_accuracy: 0.8570 - val_loss: 8.6540 - val_lplOut_loss: 2.7674 - val_dplOut_loss: 0.4400 - val_lplOut_categorical_accuracy: 0.3005 - val_dplOut_categorical_accuracy: 0.8227\n",
      "Epoch 10/10\n",
      "350/351 [============================>.] - ETA: 0s - loss: 6.1384 - lplOut_loss: 0.5064 - dplOut_loss: 0.4431 - lplOut_categorical_accuracy: 0.8157 - dplOut_categorical_accuracy: 0.81850.999909\n",
      "351/351 [==============================] - 253s - loss: 6.1375 - lplOut_loss: 0.5063 - dplOut_loss: 0.4431 - lplOut_categorical_accuracy: 0.8157 - dplOut_categorical_accuracy: 0.8186 - val_loss: 8.1159 - val_lplOut_loss: 2.6891 - val_dplOut_loss: 0.4928 - val_lplOut_categorical_accuracy: 0.3078 - val_dplOut_categorical_accuracy: 0.7809\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "265/265 [==============================] - 102s - loss: 12.0700 - categorical_accuracy: 0.2605 - val_loss: 10.9246 - val_categorical_accuracy: 0.3126\n",
      "Epoch 2/10\n",
      "265/265 [==============================] - 100s - loss: 10.0531 - categorical_accuracy: 0.2882 - val_loss: 9.3010 - val_categorical_accuracy: 0.3315\n",
      "Epoch 3/10\n",
      "265/265 [==============================] - 100s - loss: 8.6769 - categorical_accuracy: 0.2986 - val_loss: 8.1661 - val_categorical_accuracy: 0.3271\n",
      "Epoch 4/10\n",
      "265/265 [==============================] - 100s - loss: 7.6918 - categorical_accuracy: 0.3094 - val_loss: 7.3248 - val_categorical_accuracy: 0.3421\n",
      "Epoch 5/10\n",
      "265/265 [==============================] - 100s - loss: 6.9697 - categorical_accuracy: 0.3113 - val_loss: 6.7178 - val_categorical_accuracy: 0.3346\n",
      "Epoch 6/10\n",
      "265/265 [==============================] - 100s - loss: 6.3993 - categorical_accuracy: 0.3297 - val_loss: 6.2195 - val_categorical_accuracy: 0.3402\n",
      "Epoch 7/10\n",
      "265/265 [==============================] - 100s - loss: 5.9494 - categorical_accuracy: 0.3369 - val_loss: 5.8466 - val_categorical_accuracy: 0.3123\n",
      "Epoch 8/10\n",
      "265/265 [==============================] - 100s - loss: 5.5759 - categorical_accuracy: 0.3373 - val_loss: 5.5033 - val_categorical_accuracy: 0.3227\n",
      "Epoch 9/10\n",
      "265/265 [==============================] - 100s - loss: 5.2424 - categorical_accuracy: 0.3542 - val_loss: 5.2089 - val_categorical_accuracy: 0.3352\n",
      "Epoch 10/10\n",
      "265/265 [==============================] - 100s - loss: 4.9630 - categorical_accuracy: 0.3635 - val_loss: 4.9530 - val_categorical_accuracy: 0.3308\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 128s - loss: 11.2131 - categorical_accuracy: 0.5662 - val_loss: 9.3947 - val_categorical_accuracy: 0.7773\n",
      "Epoch 2/10\n",
      "351/351 [==============================] - 126s - loss: 8.6647 - categorical_accuracy: 0.7517 - val_loss: 7.8399 - val_categorical_accuracy: 0.7855\n",
      "Epoch 3/10\n",
      "351/351 [==============================] - 126s - loss: 7.3824 - categorical_accuracy: 0.7772 - val_loss: 6.8199 - val_categorical_accuracy: 0.8138\n",
      "Epoch 4/10\n",
      "351/351 [==============================] - 126s - loss: 6.5403 - categorical_accuracy: 0.7946 - val_loss: 6.1354 - val_categorical_accuracy: 0.8230\n",
      "Epoch 5/10\n",
      "351/351 [==============================] - 126s - loss: 5.9320 - categorical_accuracy: 0.8058 - val_loss: 5.6141 - val_categorical_accuracy: 0.8257\n",
      "Epoch 6/10\n",
      "351/351 [==============================] - 126s - loss: 5.4548 - categorical_accuracy: 0.8122 - val_loss: 5.2037 - val_categorical_accuracy: 0.8245\n",
      "Epoch 7/10\n",
      "351/351 [==============================] - 126s - loss: 5.0437 - categorical_accuracy: 0.8240 - val_loss: 4.8236 - val_categorical_accuracy: 0.8383\n",
      "Epoch 8/10\n",
      "351/351 [==============================] - 126s - loss: 4.6870 - categorical_accuracy: 0.8309 - val_loss: 4.4944 - val_categorical_accuracy: 0.8307\n",
      "Epoch 9/10\n",
      "351/351 [==============================] - 126s - loss: 4.3599 - categorical_accuracy: 0.8339 - val_loss: 4.1868 - val_categorical_accuracy: 0.8401\n",
      "Epoch 10/10\n",
      "351/351 [==============================] - 126s - loss: 4.0602 - categorical_accuracy: 0.8408 - val_loss: 3.9287 - val_categorical_accuracy: 0.8271\n",
      "Found 22773 images belonging to 5 classes.\n",
      "Found 17329 images belonging to 5 classes.\n",
      "Found 2960 images belonging to 5 classes.\n",
      "Found 2819 images belonging to 5 classes.\n",
      "Found 2589 images belonging to 5 classes.\n",
      "Found 2696 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n",
      "Epoch 1/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 21.0443 - lplOut_loss: 1.0924 - dplOut_loss: 0.2639 - lplOut_categorical_accuracy: 0.5668 - dplOut_categorical_accuracy: 0.90840.462117\n",
      "355/355 [==============================] - 258s - loss: 21.0343 - lplOut_loss: 1.0915 - dplOut_loss: 0.2634 - lplOut_categorical_accuracy: 0.5672 - dplOut_categorical_accuracy: 0.9086 - val_loss: 19.2702 - val_lplOut_loss: 2.4549 - val_dplOut_loss: 0.1632 - val_lplOut_categorical_accuracy: 0.2755 - val_dplOut_categorical_accuracy: 0.9307\n",
      "Epoch 2/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 15.4999 - lplOut_loss: 0.6939 - dplOut_loss: 0.1222 - lplOut_categorical_accuracy: 0.7413 - dplOut_categorical_accuracy: 0.95860.761594\n",
      "355/355 [==============================] - 257s - loss: 15.4946 - lplOut_loss: 0.6933 - dplOut_loss: 0.1221 - lplOut_categorical_accuracy: 0.7415 - dplOut_categorical_accuracy: 0.9587 - val_loss: 15.7443 - val_lplOut_loss: 2.5786 - val_dplOut_loss: 0.1454 - val_lplOut_categorical_accuracy: 0.2796 - val_dplOut_categorical_accuracy: 0.9372\n",
      "Epoch 3/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 12.5623 - lplOut_loss: 0.6099 - dplOut_loss: 0.1177 - lplOut_categorical_accuracy: 0.7717 - dplOut_categorical_accuracy: 0.96250.905148\n",
      "355/355 [==============================] - 258s - loss: 12.5592 - lplOut_loss: 0.6097 - dplOut_loss: 0.1177 - lplOut_categorical_accuracy: 0.7717 - dplOut_categorical_accuracy: 0.9625 - val_loss: 13.7175 - val_lplOut_loss: 2.7658 - val_dplOut_loss: 0.1505 - val_lplOut_categorical_accuracy: 0.2762 - val_dplOut_categorical_accuracy: 0.9355\n",
      "Epoch 4/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 10.7896 - lplOut_loss: 0.5747 - dplOut_loss: 0.1912 - lplOut_categorical_accuracy: 0.7831 - dplOut_categorical_accuracy: 0.93030.964028\n",
      "355/355 [==============================] - 257s - loss: 10.7878 - lplOut_loss: 0.5746 - dplOut_loss: 0.1913 - lplOut_categorical_accuracy: 0.7830 - dplOut_categorical_accuracy: 0.9302 - val_loss: 12.1807 - val_lplOut_loss: 2.6383 - val_dplOut_loss: 0.2090 - val_lplOut_categorical_accuracy: 0.2911 - val_dplOut_categorical_accuracy: 0.9198\n",
      "Epoch 5/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 9.6080 - lplOut_loss: 0.5606 - dplOut_loss: 0.2569 - lplOut_categorical_accuracy: 0.7905 - dplOut_categorical_accuracy: 0.90180.986614\n",
      "355/355 [==============================] - 257s - loss: 9.6067 - lplOut_loss: 0.5607 - dplOut_loss: 0.2568 - lplOut_categorical_accuracy: 0.7905 - dplOut_categorical_accuracy: 0.9018 - val_loss: 11.2080 - val_lplOut_loss: 2.7197 - val_dplOut_loss: 0.1994 - val_lplOut_categorical_accuracy: 0.2751 - val_dplOut_categorical_accuracy: 0.9372\n",
      "Epoch 6/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 8.6846 - lplOut_loss: 0.5429 - dplOut_loss: 0.2803 - lplOut_categorical_accuracy: 0.7961 - dplOut_categorical_accuracy: 0.89720.995055\n",
      "355/355 [==============================] - 257s - loss: 8.6836 - lplOut_loss: 0.5431 - dplOut_loss: 0.2802 - lplOut_categorical_accuracy: 0.7960 - dplOut_categorical_accuracy: 0.8974 - val_loss: 10.3561 - val_lplOut_loss: 2.6537 - val_dplOut_loss: 0.2473 - val_lplOut_categorical_accuracy: 0.2860 - val_dplOut_categorical_accuracy: 0.9260\n",
      "Epoch 7/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 7.9615 - lplOut_loss: 0.5287 - dplOut_loss: 0.3388 - lplOut_categorical_accuracy: 0.8027 - dplOut_categorical_accuracy: 0.87220.998178\n",
      "355/355 [==============================] - 258s - loss: 7.9606 - lplOut_loss: 0.5288 - dplOut_loss: 0.3389 - lplOut_categorical_accuracy: 0.8026 - dplOut_categorical_accuracy: 0.8722 - val_loss: 9.7733 - val_lplOut_loss: 2.6853 - val_dplOut_loss: 0.3430 - val_lplOut_categorical_accuracy: 0.2809 - val_dplOut_categorical_accuracy: 0.8672\n",
      "Epoch 8/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 7.3268 - lplOut_loss: 0.5255 - dplOut_loss: 0.3744 - lplOut_categorical_accuracy: 0.8021 - dplOut_categorical_accuracy: 0.85870.999329\n",
      "355/355 [==============================] - 257s - loss: 7.3260 - lplOut_loss: 0.5255 - dplOut_loss: 0.3745 - lplOut_categorical_accuracy: 0.8020 - dplOut_categorical_accuracy: 0.8587 - val_loss: 9.1268 - val_lplOut_loss: 2.6507 - val_dplOut_loss: 0.3599 - val_lplOut_categorical_accuracy: 0.2850 - val_dplOut_categorical_accuracy: 0.8832\n",
      "Epoch 9/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 6.7630 - lplOut_loss: 0.5210 - dplOut_loss: 0.4136 - lplOut_categorical_accuracy: 0.8074 - dplOut_categorical_accuracy: 0.84800.999753\n",
      "355/355 [==============================] - 257s - loss: 6.7623 - lplOut_loss: 0.5210 - dplOut_loss: 0.4137 - lplOut_categorical_accuracy: 0.8074 - dplOut_categorical_accuracy: 0.8479 - val_loss: 8.4929 - val_lplOut_loss: 2.5712 - val_dplOut_loss: 0.3745 - val_lplOut_categorical_accuracy: 0.2850 - val_dplOut_categorical_accuracy: 0.8777\n",
      "Epoch 10/10\n",
      "354/355 [============================>.] - ETA: 0s - loss: 6.2554 - lplOut_loss: 0.5175 - dplOut_loss: 0.4536 - lplOut_categorical_accuracy: 0.8082 - dplOut_categorical_accuracy: 0.83150.999909\n",
      "355/355 [==============================] - 258s - loss: 6.2547 - lplOut_loss: 0.5173 - dplOut_loss: 0.4538 - lplOut_categorical_accuracy: 0.8084 - dplOut_categorical_accuracy: 0.8314 - val_loss: 8.1283 - val_lplOut_loss: 2.6248 - val_dplOut_loss: 0.4781 - val_lplOut_categorical_accuracy: 0.2768 - val_dplOut_categorical_accuracy: 0.8094\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "270/270 [==============================] - 102s - loss: 12.0760 - categorical_accuracy: 0.2730 - val_loss: 11.0688 - val_categorical_accuracy: 0.2316\n",
      "Epoch 2/10\n",
      "270/270 [==============================] - 100s - loss: 10.0319 - categorical_accuracy: 0.2937 - val_loss: 9.3861 - val_categorical_accuracy: 0.2483\n",
      "Epoch 3/10\n",
      "270/270 [==============================] - 100s - loss: 8.6427 - categorical_accuracy: 0.3103 - val_loss: 8.2425 - val_categorical_accuracy: 0.2401\n",
      "Epoch 4/10\n",
      "270/270 [==============================] - 100s - loss: 7.6632 - categorical_accuracy: 0.3215 - val_loss: 7.4073 - val_categorical_accuracy: 0.2650\n",
      "Epoch 5/10\n",
      "270/270 [==============================] - 100s - loss: 6.9278 - categorical_accuracy: 0.3340 - val_loss: 6.8177 - val_categorical_accuracy: 0.2639\n",
      "Epoch 6/10\n",
      "270/270 [==============================] - 100s - loss: 6.3750 - categorical_accuracy: 0.3429 - val_loss: 6.3407 - val_categorical_accuracy: 0.2617\n",
      "Epoch 7/10\n",
      "270/270 [==============================] - 100s - loss: 5.9282 - categorical_accuracy: 0.3478 - val_loss: 5.9807 - val_categorical_accuracy: 0.2690\n",
      "Epoch 8/10\n",
      "270/270 [==============================] - 100s - loss: 5.5529 - categorical_accuracy: 0.3574 - val_loss: 5.5790 - val_categorical_accuracy: 0.2842\n",
      "Epoch 9/10\n",
      "270/270 [==============================] - 100s - loss: 5.2251 - categorical_accuracy: 0.3617 - val_loss: 5.3655 - val_categorical_accuracy: 0.2802\n",
      "Epoch 10/10\n",
      "270/270 [==============================] - 100s - loss: 4.9483 - categorical_accuracy: 0.3717 - val_loss: 5.0829 - val_categorical_accuracy: 0.2686\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "355/355 [==============================] - 129s - loss: 11.1944 - categorical_accuracy: 0.5561 - val_loss: 9.3700 - val_categorical_accuracy: 0.7987\n",
      "Epoch 2/10\n",
      "355/355 [==============================] - 128s - loss: 8.6405 - categorical_accuracy: 0.7405 - val_loss: 7.7439 - val_categorical_accuracy: 0.8191\n",
      "Epoch 3/10\n",
      "355/355 [==============================] - 128s - loss: 7.3422 - categorical_accuracy: 0.7698 - val_loss: 6.8246 - val_categorical_accuracy: 0.8056\n",
      "Epoch 4/10\n",
      "355/355 [==============================] - 129s - loss: 6.4955 - categorical_accuracy: 0.7882 - val_loss: 6.0923 - val_categorical_accuracy: 0.8336\n",
      "Epoch 5/10\n",
      "355/355 [==============================] - 128s - loss: 5.8798 - categorical_accuracy: 0.8018 - val_loss: 5.6481 - val_categorical_accuracy: 0.8063\n",
      "Epoch 6/10\n",
      "355/355 [==============================] - 128s - loss: 5.4002 - categorical_accuracy: 0.8046 - val_loss: 5.1776 - val_categorical_accuracy: 0.8270\n",
      "Epoch 7/10\n",
      "355/355 [==============================] - 128s - loss: 4.9904 - categorical_accuracy: 0.8125 - val_loss: 4.7967 - val_categorical_accuracy: 0.8374\n",
      "Epoch 8/10\n",
      "355/355 [==============================] - 129s - loss: 4.6266 - categorical_accuracy: 0.8222 - val_loss: 4.4761 - val_categorical_accuracy: 0.8291\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - 129s - loss: 4.2956 - categorical_accuracy: 0.8259 - val_loss: 4.1891 - val_categorical_accuracy: 0.8319\n",
      "Epoch 10/10\n",
      "355/355 [==============================] - 128s - loss: 3.9900 - categorical_accuracy: 0.8327 - val_loss: 3.9015 - val_categorical_accuracy: 0.8322\n",
      "Found 22544 images belonging to 5 classes.\n",
      "Found 18087 images belonging to 5 classes.\n",
      "Found 2489 images belonging to 5 classes.\n",
      "Found 2757 images belonging to 5 classes.\n",
      "Found 3310 images belonging to 5 classes.\n",
      "Found 2341 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n",
      "Epoch 1/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 21.0804 - lplOut_loss: 1.1023 - dplOut_loss: 0.2475 - lplOut_categorical_accuracy: 0.5661 - dplOut_categorical_accuracy: 0.91720.462117\n",
      "352/352 [==============================] - 251s - loss: 21.0704 - lplOut_loss: 1.1014 - dplOut_loss: 0.2470 - lplOut_categorical_accuracy: 0.5664 - dplOut_categorical_accuracy: 0.9174 - val_loss: 19.1021 - val_lplOut_loss: 2.3186 - val_dplOut_loss: 0.0802 - val_lplOut_categorical_accuracy: 0.3133 - val_dplOut_categorical_accuracy: 0.9749\n",
      "Epoch 2/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 15.4953 - lplOut_loss: 0.6572 - dplOut_loss: 0.1042 - lplOut_categorical_accuracy: 0.7582 - dplOut_categorical_accuracy: 0.96530.761594\n",
      "352/352 [==============================] - 251s - loss: 15.4901 - lplOut_loss: 0.6568 - dplOut_loss: 0.1042 - lplOut_categorical_accuracy: 0.7582 - dplOut_categorical_accuracy: 0.9653 - val_loss: 15.7828 - val_lplOut_loss: 2.6367 - val_dplOut_loss: 0.0733 - val_lplOut_categorical_accuracy: 0.3092 - val_dplOut_categorical_accuracy: 0.9745\n",
      "Epoch 3/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 12.5789 - lplOut_loss: 0.5892 - dplOut_loss: 0.1031 - lplOut_categorical_accuracy: 0.7780 - dplOut_categorical_accuracy: 0.96700.905148\n",
      "352/352 [==============================] - 250s - loss: 12.5762 - lplOut_loss: 0.5894 - dplOut_loss: 0.1031 - lplOut_categorical_accuracy: 0.7778 - dplOut_categorical_accuracy: 0.9671 - val_loss: 13.6242 - val_lplOut_loss: 2.7046 - val_dplOut_loss: 0.0702 - val_lplOut_categorical_accuracy: 0.3084 - val_dplOut_categorical_accuracy: 0.9803\n",
      "Epoch 4/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 10.7777 - lplOut_loss: 0.5512 - dplOut_loss: 0.1612 - lplOut_categorical_accuracy: 0.7941 - dplOut_categorical_accuracy: 0.94540.964028\n",
      "352/352 [==============================] - 250s - loss: 10.7762 - lplOut_loss: 0.5514 - dplOut_loss: 0.1615 - lplOut_categorical_accuracy: 0.7939 - dplOut_categorical_accuracy: 0.9452 - val_loss: 12.1565 - val_lplOut_loss: 2.6260 - val_dplOut_loss: 0.1620 - val_lplOut_categorical_accuracy: 0.3113 - val_dplOut_categorical_accuracy: 0.9515\n",
      "Epoch 5/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 9.6099 - lplOut_loss: 0.5371 - dplOut_loss: 0.2519 - lplOut_categorical_accuracy: 0.8010 - dplOut_categorical_accuracy: 0.90410.986614\n",
      "352/352 [==============================] - 250s - loss: 9.6084 - lplOut_loss: 0.5370 - dplOut_loss: 0.2520 - lplOut_categorical_accuracy: 0.8011 - dplOut_categorical_accuracy: 0.9042 - val_loss: 11.1579 - val_lplOut_loss: 2.6341 - val_dplOut_loss: 0.2063 - val_lplOut_categorical_accuracy: 0.3104 - val_dplOut_categorical_accuracy: 0.9239\n",
      "Epoch 6/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 8.6814 - lplOut_loss: 0.5263 - dplOut_loss: 0.2643 - lplOut_categorical_accuracy: 0.8036 - dplOut_categorical_accuracy: 0.90680.995055\n",
      "352/352 [==============================] - 250s - loss: 8.6803 - lplOut_loss: 0.5266 - dplOut_loss: 0.2642 - lplOut_categorical_accuracy: 0.8036 - dplOut_categorical_accuracy: 0.9070 - val_loss: 10.3519 - val_lplOut_loss: 2.6195 - val_dplOut_loss: 0.2472 - val_lplOut_categorical_accuracy: 0.3183 - val_dplOut_categorical_accuracy: 0.9108\n",
      "Epoch 7/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 7.9576 - lplOut_loss: 0.5156 - dplOut_loss: 0.3183 - lplOut_categorical_accuracy: 0.8100 - dplOut_categorical_accuracy: 0.88320.998178\n",
      "352/352 [==============================] - 250s - loss: 7.9567 - lplOut_loss: 0.5156 - dplOut_loss: 0.3184 - lplOut_categorical_accuracy: 0.8100 - dplOut_categorical_accuracy: 0.8832 - val_loss: 9.6761 - val_lplOut_loss: 2.5894 - val_dplOut_loss: 0.3129 - val_lplOut_categorical_accuracy: 0.3236 - val_dplOut_categorical_accuracy: 0.8902\n",
      "Epoch 8/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 7.3402 - lplOut_loss: 0.5128 - dplOut_loss: 0.3721 - lplOut_categorical_accuracy: 0.8113 - dplOut_categorical_accuracy: 0.86080.999329\n",
      "352/352 [==============================] - 250s - loss: 7.3396 - lplOut_loss: 0.5128 - dplOut_loss: 0.3724 - lplOut_categorical_accuracy: 0.8112 - dplOut_categorical_accuracy: 0.8605 - val_loss: 9.0839 - val_lplOut_loss: 2.5481 - val_dplOut_loss: 0.3907 - val_lplOut_categorical_accuracy: 0.3018 - val_dplOut_categorical_accuracy: 0.8495\n",
      "Epoch 9/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 6.7933 - lplOut_loss: 0.5055 - dplOut_loss: 0.4311 - lplOut_categorical_accuracy: 0.8157 - dplOut_categorical_accuracy: 0.83220.999753\n",
      "352/352 [==============================] - 251s - loss: 6.7925 - lplOut_loss: 0.5053 - dplOut_loss: 0.4313 - lplOut_categorical_accuracy: 0.8159 - dplOut_categorical_accuracy: 0.8320 - val_loss: 8.4736 - val_lplOut_loss: 2.4683 - val_dplOut_loss: 0.4318 - val_lplOut_categorical_accuracy: 0.3215 - val_dplOut_categorical_accuracy: 0.8454\n",
      "Epoch 10/10\n",
      "351/352 [============================>.] - ETA: 0s - loss: 6.2672 - lplOut_loss: 0.4998 - dplOut_loss: 0.4577 - lplOut_categorical_accuracy: 0.8181 - dplOut_categorical_accuracy: 0.82240.999909\n",
      "352/352 [==============================] - 251s - loss: 6.2661 - lplOut_loss: 0.4995 - dplOut_loss: 0.4576 - lplOut_categorical_accuracy: 0.8182 - dplOut_categorical_accuracy: 0.8226 - val_loss: 7.9936 - val_lplOut_loss: 2.5047 - val_dplOut_loss: 0.4378 - val_lplOut_categorical_accuracy: 0.3055 - val_dplOut_categorical_accuracy: 0.8561\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "282/282 [==============================] - 105s - loss: 11.9711 - categorical_accuracy: 0.2738 - val_loss: 10.8824 - val_categorical_accuracy: 0.2306\n",
      "Epoch 2/10\n",
      "282/282 [==============================] - 103s - loss: 9.8531 - categorical_accuracy: 0.3068 - val_loss: 9.2022 - val_categorical_accuracy: 0.2748\n",
      "Epoch 3/10\n",
      "282/282 [==============================] - 104s - loss: 8.4516 - categorical_accuracy: 0.3155 - val_loss: 8.0560 - val_categorical_accuracy: 0.2837\n",
      "Epoch 4/10\n",
      "282/282 [==============================] - 104s - loss: 7.4522 - categorical_accuracy: 0.3398 - val_loss: 7.2790 - val_categorical_accuracy: 0.2250\n",
      "Epoch 5/10\n",
      "282/282 [==============================] - 104s - loss: 6.7361 - categorical_accuracy: 0.3429 - val_loss: 6.6565 - val_categorical_accuracy: 0.2674\n",
      "Epoch 6/10\n",
      "282/282 [==============================] - 104s - loss: 6.1762 - categorical_accuracy: 0.3613 - val_loss: 6.1709 - val_categorical_accuracy: 0.2848\n",
      "Epoch 7/10\n",
      "282/282 [==============================] - 104s - loss: 5.7388 - categorical_accuracy: 0.3639 - val_loss: 5.8196 - val_categorical_accuracy: 0.2481\n",
      "Epoch 8/10\n",
      "282/282 [==============================] - 104s - loss: 5.3737 - categorical_accuracy: 0.3752 - val_loss: 5.5291 - val_categorical_accuracy: 0.2674\n",
      "Epoch 9/10\n",
      "282/282 [==============================] - 104s - loss: 5.0482 - categorical_accuracy: 0.3876 - val_loss: 5.2625 - val_categorical_accuracy: 0.2722\n",
      "Epoch 10/10\n",
      "282/282 [==============================] - 104s - loss: 4.7674 - categorical_accuracy: 0.3928 - val_loss: 4.9794 - val_categorical_accuracy: 0.2618\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "352/352 [==============================] - 127s - loss: 11.1877 - categorical_accuracy: 0.5703 - val_loss: 9.5304 - val_categorical_accuracy: 0.7126\n",
      "Epoch 2/10\n",
      "352/352 [==============================] - 125s - loss: 8.6464 - categorical_accuracy: 0.7529 - val_loss: 7.8965 - val_categorical_accuracy: 0.7522\n",
      "Epoch 3/10\n",
      "352/352 [==============================] - 125s - loss: 7.3574 - categorical_accuracy: 0.7818 - val_loss: 6.8864 - val_categorical_accuracy: 0.7740\n",
      "Epoch 4/10\n",
      "352/352 [==============================] - 125s - loss: 6.5198 - categorical_accuracy: 0.7956 - val_loss: 6.1879 - val_categorical_accuracy: 0.7901\n",
      "Epoch 5/10\n",
      "352/352 [==============================] - 125s - loss: 5.9054 - categorical_accuracy: 0.8043 - val_loss: 5.6823 - val_categorical_accuracy: 0.7823\n",
      "Epoch 6/10\n",
      "352/352 [==============================] - 125s - loss: 5.4172 - categorical_accuracy: 0.8176 - val_loss: 5.2633 - val_categorical_accuracy: 0.7839\n",
      "Epoch 7/10\n",
      "352/352 [==============================] - 125s - loss: 4.9988 - categorical_accuracy: 0.8229 - val_loss: 4.8289 - val_categorical_accuracy: 0.7979\n",
      "Epoch 8/10\n",
      "352/352 [==============================] - 125s - loss: 4.6348 - categorical_accuracy: 0.8295 - val_loss: 4.5088 - val_categorical_accuracy: 0.7992\n",
      "Epoch 9/10\n",
      "352/352 [==============================] - 125s - loss: 4.3024 - categorical_accuracy: 0.8357 - val_loss: 4.1840 - val_categorical_accuracy: 0.8016\n",
      "Epoch 10/10\n",
      "352/352 [==============================] - 125s - loss: 4.0014 - categorical_accuracy: 0.8379 - val_loss: 3.8730 - val_categorical_accuracy: 0.8107\n",
      "Found 22928 images belonging to 5 classes.\n",
      "Found 18190 images belonging to 5 classes.\n",
      "Found 3083 images belonging to 5 classes.\n",
      "Found 2447 images belonging to 5 classes.\n",
      "Found 2311 images belonging to 5 classes.\n",
      "Found 2207 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 21.0359 - lplOut_loss: 1.0997 - dplOut_loss: 0.2519 - lplOut_categorical_accuracy: 0.5632 - dplOut_categorical_accuracy: 0.91070.462117\n",
      "358/358 [==============================] - 262s - loss: 21.0260 - lplOut_loss: 1.0985 - dplOut_loss: 0.2516 - lplOut_categorical_accuracy: 0.5636 - dplOut_categorical_accuracy: 0.9108 - val_loss: 19.6616 - val_lplOut_loss: 2.6854 - val_dplOut_loss: 0.3296 - val_lplOut_categorical_accuracy: 0.2835 - val_dplOut_categorical_accuracy: 0.8454\n",
      "Epoch 2/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 15.4431 - lplOut_loss: 0.6528 - dplOut_loss: 0.1155 - lplOut_categorical_accuracy: 0.7553 - dplOut_categorical_accuracy: 0.96090.761594\n",
      "358/358 [==============================] - 262s - loss: 15.4381 - lplOut_loss: 0.6525 - dplOut_loss: 0.1154 - lplOut_categorical_accuracy: 0.7555 - dplOut_categorical_accuracy: 0.9610 - val_loss: 16.1685 - val_lplOut_loss: 2.9609 - val_dplOut_loss: 0.1977 - val_lplOut_categorical_accuracy: 0.2972 - val_dplOut_categorical_accuracy: 0.9176\n",
      "Epoch 3/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 12.5158 - lplOut_loss: 0.5822 - dplOut_loss: 0.1089 - lplOut_categorical_accuracy: 0.7834 - dplOut_categorical_accuracy: 0.96410.905148\n",
      "358/358 [==============================] - 260s - loss: 12.5131 - lplOut_loss: 0.5823 - dplOut_loss: 0.1089 - lplOut_categorical_accuracy: 0.7834 - dplOut_categorical_accuracy: 0.9640 - val_loss: 14.0827 - val_lplOut_loss: 3.0366 - val_dplOut_loss: 0.2544 - val_lplOut_categorical_accuracy: 0.2868 - val_dplOut_categorical_accuracy: 0.8893\n",
      "Epoch 4/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 10.6935 - lplOut_loss: 0.5383 - dplOut_loss: 0.1448 - lplOut_categorical_accuracy: 0.7964 - dplOut_categorical_accuracy: 0.94960.964028\n",
      "358/358 [==============================] - 261s - loss: 10.6911 - lplOut_loss: 0.5376 - dplOut_loss: 0.1450 - lplOut_categorical_accuracy: 0.7968 - dplOut_categorical_accuracy: 0.9495 - val_loss: 12.8397 - val_lplOut_loss: 3.1223 - val_dplOut_loss: 0.4058 - val_lplOut_categorical_accuracy: 0.2881 - val_dplOut_categorical_accuracy: 0.8008\n",
      "Epoch 5/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 9.4858 - lplOut_loss: 0.5263 - dplOut_loss: 0.2018 - lplOut_categorical_accuracy: 0.8036 - dplOut_categorical_accuracy: 0.92570.986614\n",
      "358/358 [==============================] - 260s - loss: 9.4842 - lplOut_loss: 0.5261 - dplOut_loss: 0.2018 - lplOut_categorical_accuracy: 0.8037 - dplOut_categorical_accuracy: 0.9256 - val_loss: 11.7656 - val_lplOut_loss: 3.0490 - val_dplOut_loss: 0.4677 - val_lplOut_categorical_accuracy: 0.3102 - val_dplOut_categorical_accuracy: 0.7770\n",
      "Epoch 6/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 8.5609 - lplOut_loss: 0.5136 - dplOut_loss: 0.2280 - lplOut_categorical_accuracy: 0.8100 - dplOut_categorical_accuracy: 0.91940.995055\n",
      "358/358 [==============================] - 261s - loss: 8.5602 - lplOut_loss: 0.5139 - dplOut_loss: 0.2282 - lplOut_categorical_accuracy: 0.8098 - dplOut_categorical_accuracy: 0.9193 - val_loss: 10.9058 - val_lplOut_loss: 3.0097 - val_dplOut_loss: 0.4837 - val_lplOut_categorical_accuracy: 0.3148 - val_dplOut_categorical_accuracy: 0.7822\n",
      "Epoch 7/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 7.8213 - lplOut_loss: 0.5054 - dplOut_loss: 0.2646 - lplOut_categorical_accuracy: 0.8123 - dplOut_categorical_accuracy: 0.90550.998178\n",
      "358/358 [==============================] - 261s - loss: 7.8204 - lplOut_loss: 0.5052 - dplOut_loss: 0.2648 - lplOut_categorical_accuracy: 0.8124 - dplOut_categorical_accuracy: 0.9052 - val_loss: 10.1575 - val_lplOut_loss: 2.9868 - val_dplOut_loss: 0.4682 - val_lplOut_categorical_accuracy: 0.3271 - val_dplOut_categorical_accuracy: 0.7910\n",
      "Epoch 8/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 7.2192 - lplOut_loss: 0.4998 - dplOut_loss: 0.3348 - lplOut_categorical_accuracy: 0.8160 - dplOut_categorical_accuracy: 0.87940.999329\n",
      "358/358 [==============================] - 261s - loss: 7.2186 - lplOut_loss: 0.5000 - dplOut_loss: 0.3348 - lplOut_categorical_accuracy: 0.8159 - dplOut_categorical_accuracy: 0.8794 - val_loss: 9.6259 - val_lplOut_loss: 2.9649 - val_dplOut_loss: 0.5858 - val_lplOut_categorical_accuracy: 0.3203 - val_dplOut_categorical_accuracy: 0.7178\n",
      "Epoch 9/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 6.6688 - lplOut_loss: 0.4996 - dplOut_loss: 0.3798 - lplOut_categorical_accuracy: 0.8143 - dplOut_categorical_accuracy: 0.86000.999753\n",
      "358/358 [==============================] - 261s - loss: 6.6681 - lplOut_loss: 0.4997 - dplOut_loss: 0.3798 - lplOut_categorical_accuracy: 0.8142 - dplOut_categorical_accuracy: 0.8600 - val_loss: 8.9269 - val_lplOut_loss: 2.8938 - val_dplOut_loss: 0.5244 - val_lplOut_categorical_accuracy: 0.3311 - val_dplOut_categorical_accuracy: 0.7507\n",
      "Epoch 10/10\n",
      "357/358 [============================>.] - ETA: 0s - loss: 6.1812 - lplOut_loss: 0.5007 - dplOut_loss: 0.4331 - lplOut_categorical_accuracy: 0.8160 - dplOut_categorical_accuracy: 0.83210.999909\n",
      "358/358 [==============================] - 261s - loss: 6.1806 - lplOut_loss: 0.5009 - dplOut_loss: 0.4331 - lplOut_categorical_accuracy: 0.8159 - dplOut_categorical_accuracy: 0.8322 - val_loss: 8.4565 - val_lplOut_loss: 2.9176 - val_dplOut_loss: 0.5486 - val_lplOut_categorical_accuracy: 0.3164 - val_dplOut_categorical_accuracy: 0.7380\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 104s - loss: 11.9783 - categorical_accuracy: 0.2606 - val_loss: 10.7677 - val_categorical_accuracy: 0.2820\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 100s - loss: 9.8833 - categorical_accuracy: 0.2894 - val_loss: 9.0991 - val_categorical_accuracy: 0.3311\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 100s - loss: 8.4867 - categorical_accuracy: 0.3010 - val_loss: 7.9696 - val_categorical_accuracy: 0.3382\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 100s - loss: 7.5150 - categorical_accuracy: 0.3034 - val_loss: 7.1518 - val_categorical_accuracy: 0.3261\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 103s - loss: 6.7881 - categorical_accuracy: 0.3196 - val_loss: 6.5253 - val_categorical_accuracy: 0.3370\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 103s - loss: 6.2402 - categorical_accuracy: 0.3286 - val_loss: 6.0410 - val_categorical_accuracy: 0.3475\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 103s - loss: 5.7953 - categorical_accuracy: 0.3323 - val_loss: 5.6548 - val_categorical_accuracy: 0.3336\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 103s - loss: 5.4231 - categorical_accuracy: 0.3420 - val_loss: 5.3235 - val_categorical_accuracy: 0.3198\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 103s - loss: 5.0904 - categorical_accuracy: 0.3533 - val_loss: 5.0237 - val_categorical_accuracy: 0.3328\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 103s - loss: 4.8136 - categorical_accuracy: 0.3558 - val_loss: 4.7745 - val_categorical_accuracy: 0.3386\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "358/358 [==============================] - 131s - loss: 11.1703 - categorical_accuracy: 0.5698 - val_loss: 9.3202 - val_categorical_accuracy: 0.8089\n",
      "Epoch 2/10\n",
      "358/358 [==============================] - 130s - loss: 8.5879 - categorical_accuracy: 0.7579 - val_loss: 7.6852 - val_categorical_accuracy: 0.8387\n",
      "Epoch 3/10\n",
      "358/358 [==============================] - 130s - loss: 7.2800 - categorical_accuracy: 0.7867 - val_loss: 6.7502 - val_categorical_accuracy: 0.8069\n",
      "Epoch 4/10\n",
      "358/358 [==============================] - 129s - loss: 6.4311 - categorical_accuracy: 0.8003 - val_loss: 6.0640 - val_categorical_accuracy: 0.8172\n",
      "Epoch 5/10\n",
      "358/358 [==============================] - 128s - loss: 5.8175 - categorical_accuracy: 0.8076 - val_loss: 5.5192 - val_categorical_accuracy: 0.8264\n",
      "Epoch 6/10\n",
      "358/358 [==============================] - 128s - loss: 5.3273 - categorical_accuracy: 0.8187 - val_loss: 5.1646 - val_categorical_accuracy: 0.7953\n",
      "Epoch 7/10\n",
      "358/358 [==============================] - 130s - loss: 4.9119 - categorical_accuracy: 0.8256 - val_loss: 4.7682 - val_categorical_accuracy: 0.8092\n",
      "Epoch 8/10\n",
      "358/358 [==============================] - 130s - loss: 4.5468 - categorical_accuracy: 0.8311 - val_loss: 4.4061 - val_categorical_accuracy: 0.8168\n",
      "Epoch 9/10\n",
      "358/358 [==============================] - 130s - loss: 4.2151 - categorical_accuracy: 0.8352 - val_loss: 4.1110 - val_categorical_accuracy: 0.8162\n",
      "Epoch 10/10\n",
      "358/358 [==============================] - 130s - loss: 3.9153 - categorical_accuracy: 0.8376 - val_loss: 3.8590 - val_categorical_accuracy: 0.8079\n",
      "Found 23413 images belonging to 5 classes.\n",
      "Found 18552 images belonging to 5 classes.\n",
      "Found 2859 images belonging to 5 classes.\n",
      "Found 1987 images belonging to 5 classes.\n",
      "Found 2173 images belonging to 5 classes.\n",
      "Found 2417 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n",
      "Epoch 1/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 20.9213 - lplOut_loss: 1.0750 - dplOut_loss: 0.2744 - lplOut_categorical_accuracy: 0.5731 - dplOut_categorical_accuracy: 0.90000.462117\n",
      "365/365 [==============================] - 261s - loss: 20.9113 - lplOut_loss: 1.0738 - dplOut_loss: 0.2740 - lplOut_categorical_accuracy: 0.5734 - dplOut_categorical_accuracy: 0.9001 - val_loss: 19.4365 - val_lplOut_loss: 2.8801 - val_dplOut_loss: 0.0915 - val_lplOut_categorical_accuracy: 0.2908 - val_dplOut_categorical_accuracy: 0.9787\n",
      "Epoch 2/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 15.2528 - lplOut_loss: 0.6547 - dplOut_loss: 0.1299 - lplOut_categorical_accuracy: 0.7538 - dplOut_categorical_accuracy: 0.95450.761594\n",
      "365/365 [==============================] - 262s - loss: 15.2481 - lplOut_loss: 0.6545 - dplOut_loss: 0.1299 - lplOut_categorical_accuracy: 0.7540 - dplOut_categorical_accuracy: 0.9544 - val_loss: 16.3352 - val_lplOut_loss: 3.4460 - val_dplOut_loss: 0.0997 - val_lplOut_categorical_accuracy: 0.2873 - val_dplOut_categorical_accuracy: 0.9741\n",
      "Epoch 3/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 12.2996 - lplOut_loss: 0.5784 - dplOut_loss: 0.1258 - lplOut_categorical_accuracy: 0.7836 - dplOut_categorical_accuracy: 0.95700.905148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 262s - loss: 12.2968 - lplOut_loss: 0.5785 - dplOut_loss: 0.1259 - lplOut_categorical_accuracy: 0.7836 - dplOut_categorical_accuracy: 0.9570 - val_loss: 14.2531 - val_lplOut_loss: 3.5720 - val_dplOut_loss: 0.1255 - val_lplOut_categorical_accuracy: 0.2685 - val_dplOut_categorical_accuracy: 0.9670\n",
      "Epoch 4/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 10.4997 - lplOut_loss: 0.5435 - dplOut_loss: 0.1826 - lplOut_categorical_accuracy: 0.7964 - dplOut_categorical_accuracy: 0.93430.964028\n",
      "365/365 [==============================] - 261s - loss: 10.4976 - lplOut_loss: 0.5432 - dplOut_loss: 0.1827 - lplOut_categorical_accuracy: 0.7966 - dplOut_categorical_accuracy: 0.9342 - val_loss: 12.8667 - val_lplOut_loss: 3.5664 - val_dplOut_loss: 0.2238 - val_lplOut_categorical_accuracy: 0.2876 - val_dplOut_categorical_accuracy: 0.9197\n",
      "Epoch 5/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 9.3024 - lplOut_loss: 0.5257 - dplOut_loss: 0.2479 - lplOut_categorical_accuracy: 0.8015 - dplOut_categorical_accuracy: 0.90410.986614\n",
      "365/365 [==============================] - 261s - loss: 9.3012 - lplOut_loss: 0.5256 - dplOut_loss: 0.2482 - lplOut_categorical_accuracy: 0.8016 - dplOut_categorical_accuracy: 0.9039 - val_loss: 11.6110 - val_lplOut_loss: 3.3803 - val_dplOut_loss: 0.2058 - val_lplOut_categorical_accuracy: 0.2947 - val_dplOut_categorical_accuracy: 0.9432\n",
      "Epoch 6/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 8.3713 - lplOut_loss: 0.5158 - dplOut_loss: 0.2584 - lplOut_categorical_accuracy: 0.8065 - dplOut_categorical_accuracy: 0.90470.995055\n",
      "365/365 [==============================] - 262s - loss: 8.3702 - lplOut_loss: 0.5156 - dplOut_loss: 0.2586 - lplOut_categorical_accuracy: 0.8065 - dplOut_categorical_accuracy: 0.9045 - val_loss: 10.7757 - val_lplOut_loss: 3.3215 - val_dplOut_loss: 0.2634 - val_lplOut_categorical_accuracy: 0.3043 - val_dplOut_categorical_accuracy: 0.9219\n",
      "Epoch 7/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 7.6380 - lplOut_loss: 0.5064 - dplOut_loss: 0.3017 - lplOut_categorical_accuracy: 0.8100 - dplOut_categorical_accuracy: 0.88830.998178\n",
      "365/365 [==============================] - 262s - loss: 7.6369 - lplOut_loss: 0.5063 - dplOut_loss: 0.3017 - lplOut_categorical_accuracy: 0.8101 - dplOut_categorical_accuracy: 0.8884 - val_loss: 10.0478 - val_lplOut_loss: 3.2188 - val_dplOut_loss: 0.3474 - val_lplOut_categorical_accuracy: 0.3079 - val_dplOut_categorical_accuracy: 0.8754\n",
      "Epoch 8/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 7.0097 - lplOut_loss: 0.5075 - dplOut_loss: 0.3376 - lplOut_categorical_accuracy: 0.8145 - dplOut_categorical_accuracy: 0.87900.999329\n",
      "365/365 [==============================] - 262s - loss: 7.0089 - lplOut_loss: 0.5075 - dplOut_loss: 0.3376 - lplOut_categorical_accuracy: 0.8145 - dplOut_categorical_accuracy: 0.8789 - val_loss: 9.4205 - val_lplOut_loss: 3.1521 - val_dplOut_loss: 0.4131 - val_lplOut_categorical_accuracy: 0.3125 - val_dplOut_categorical_accuracy: 0.8274\n",
      "Epoch 9/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 6.4613 - lplOut_loss: 0.4971 - dplOut_loss: 0.3952 - lplOut_categorical_accuracy: 0.8180 - dplOut_categorical_accuracy: 0.85240.999753\n",
      "365/365 [==============================] - 262s - loss: 6.4606 - lplOut_loss: 0.4972 - dplOut_loss: 0.3952 - lplOut_categorical_accuracy: 0.8179 - dplOut_categorical_accuracy: 0.8524 - val_loss: 9.0096 - val_lplOut_loss: 3.1865 - val_dplOut_loss: 0.5354 - val_lplOut_categorical_accuracy: 0.3104 - val_dplOut_categorical_accuracy: 0.7408\n",
      "Epoch 10/10\n",
      "364/365 [============================>.] - ETA: 0s - loss: 5.9708 - lplOut_loss: 0.4962 - dplOut_loss: 0.4494 - lplOut_categorical_accuracy: 0.8160 - dplOut_categorical_accuracy: 0.82440.999909\n",
      "365/365 [==============================] - 262s - loss: 5.9705 - lplOut_loss: 0.4964 - dplOut_loss: 0.4494 - lplOut_categorical_accuracy: 0.8160 - dplOut_categorical_accuracy: 0.8245 - val_loss: 8.4838 - val_lplOut_loss: 3.1177 - val_dplOut_loss: 0.5981 - val_lplOut_categorical_accuracy: 0.3246 - val_dplOut_categorical_accuracy: 0.6701\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 103s - loss: 11.9854 - categorical_accuracy: 0.2531 - val_loss: 10.6577 - val_categorical_accuracy: 0.3661\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 102s - loss: 9.8537 - categorical_accuracy: 0.2932 - val_loss: 8.9619 - val_categorical_accuracy: 0.3151\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 102s - loss: 8.4398 - categorical_accuracy: 0.2968 - val_loss: 7.8231 - val_categorical_accuracy: 0.2923\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 102s - loss: 7.4406 - categorical_accuracy: 0.3207 - val_loss: 6.9720 - val_categorical_accuracy: 0.3011\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 102s - loss: 6.7198 - categorical_accuracy: 0.3220 - val_loss: 6.3532 - val_categorical_accuracy: 0.3271\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 102s - loss: 6.1555 - categorical_accuracy: 0.3387 - val_loss: 5.8676 - val_categorical_accuracy: 0.2975\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 102s - loss: 5.7062 - categorical_accuracy: 0.3419 - val_loss: 5.4954 - val_categorical_accuracy: 0.2954\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 103s - loss: 5.3322 - categorical_accuracy: 0.3470 - val_loss: 5.1556 - val_categorical_accuracy: 0.2704\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 102s - loss: 4.9962 - categorical_accuracy: 0.3614 - val_loss: 4.8759 - val_categorical_accuracy: 0.2689\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 102s - loss: 4.7129 - categorical_accuracy: 0.3672 - val_loss: 4.6165 - val_categorical_accuracy: 0.2595\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365/365 [==============================] - 133s - loss: 11.1302 - categorical_accuracy: 0.5763 - val_loss: 9.5241 - val_categorical_accuracy: 0.7506\n",
      "Epoch 2/10\n",
      "365/365 [==============================] - 131s - loss: 8.5670 - categorical_accuracy: 0.7578 - val_loss: 7.9185 - val_categorical_accuracy: 0.7707\n",
      "Epoch 3/10\n",
      "365/365 [==============================] - 131s - loss: 7.2767 - categorical_accuracy: 0.7836 - val_loss: 6.9445 - val_categorical_accuracy: 0.7810\n",
      "Epoch 4/10\n",
      "365/365 [==============================] - 131s - loss: 6.4290 - categorical_accuracy: 0.7988 - val_loss: 6.2265 - val_categorical_accuracy: 0.7860\n",
      "Epoch 5/10\n",
      "365/365 [==============================] - 131s - loss: 5.8191 - categorical_accuracy: 0.8084 - val_loss: 5.7097 - val_categorical_accuracy: 0.7925\n",
      "Epoch 6/10\n",
      "365/365 [==============================] - 131s - loss: 5.3269 - categorical_accuracy: 0.8158 - val_loss: 5.2510 - val_categorical_accuracy: 0.7932\n",
      "Epoch 7/10\n",
      "365/365 [==============================] - 131s - loss: 4.9057 - categorical_accuracy: 0.8263 - val_loss: 4.9085 - val_categorical_accuracy: 0.7925\n",
      "Epoch 8/10\n",
      "365/365 [==============================] - 131s - loss: 4.5399 - categorical_accuracy: 0.8335 - val_loss: 4.5641 - val_categorical_accuracy: 0.7936\n",
      "Epoch 9/10\n",
      "365/365 [==============================] - 131s - loss: 4.2077 - categorical_accuracy: 0.8390 - val_loss: 4.2414 - val_categorical_accuracy: 0.8043\n",
      "Epoch 10/10\n",
      "365/365 [==============================] - 131s - loss: 3.9035 - categorical_accuracy: 0.8418 - val_loss: 3.9629 - val_categorical_accuracy: 0.7982\n",
      "Found 22378 images belonging to 5 classes.\n",
      "Found 18457 images belonging to 5 classes.\n",
      "Found 2878 images belonging to 5 classes.\n",
      "Found 2154 images belonging to 5 classes.\n",
      "Found 3066 images belonging to 5 classes.\n",
      "Found 2392 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n",
      "Epoch 1/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 21.1160 - lplOut_loss: 1.1425 - dplOut_loss: 0.2622 - lplOut_categorical_accuracy: 0.5412 - dplOut_categorical_accuracy: 0.90700.462117\n",
      "349/349 [==============================] - 253s - loss: 21.1062 - lplOut_loss: 1.1417 - dplOut_loss: 0.2617 - lplOut_categorical_accuracy: 0.5416 - dplOut_categorical_accuracy: 0.9071 - val_loss: 19.3386 - val_lplOut_loss: 2.4444 - val_dplOut_loss: 0.1855 - val_lplOut_categorical_accuracy: 0.3015 - val_dplOut_categorical_accuracy: 0.9261\n",
      "Epoch 2/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 15.5899 - lplOut_loss: 0.6956 - dplOut_loss: 0.1293 - lplOut_categorical_accuracy: 0.7364 - dplOut_categorical_accuracy: 0.95300.761594\n",
      "349/349 [==============================] - 252s - loss: 15.5854 - lplOut_loss: 0.6957 - dplOut_loss: 0.1293 - lplOut_categorical_accuracy: 0.7363 - dplOut_categorical_accuracy: 0.9529 - val_loss: 15.9877 - val_lplOut_loss: 2.7089 - val_dplOut_loss: 0.1585 - val_lplOut_categorical_accuracy: 0.2848 - val_dplOut_categorical_accuracy: 0.9339\n",
      "Epoch 3/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 12.6827 - lplOut_loss: 0.6137 - dplOut_loss: 0.1220 - lplOut_categorical_accuracy: 0.7681 - dplOut_categorical_accuracy: 0.95760.905148\n",
      "349/349 [==============================] - 251s - loss: 12.6794 - lplOut_loss: 0.6133 - dplOut_loss: 0.1220 - lplOut_categorical_accuracy: 0.7683 - dplOut_categorical_accuracy: 0.9577 - val_loss: 13.9047 - val_lplOut_loss: 2.8022 - val_dplOut_loss: 0.1812 - val_lplOut_categorical_accuracy: 0.2791 - val_dplOut_categorical_accuracy: 0.9258\n",
      "Epoch 4/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 10.8977 - lplOut_loss: 0.5737 - dplOut_loss: 0.1776 - lplOut_categorical_accuracy: 0.7812 - dplOut_categorical_accuracy: 0.93270.964028\n",
      "349/349 [==============================] - 251s - loss: 10.8956 - lplOut_loss: 0.5736 - dplOut_loss: 0.1775 - lplOut_categorical_accuracy: 0.7813 - dplOut_categorical_accuracy: 0.9327 - val_loss: 12.6423 - val_lplOut_loss: 2.8998 - val_dplOut_loss: 0.2870 - val_lplOut_categorical_accuracy: 0.2756 - val_dplOut_categorical_accuracy: 0.8704\n",
      "Epoch 5/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 9.7209 - lplOut_loss: 0.5615 - dplOut_loss: 0.2498 - lplOut_categorical_accuracy: 0.7843 - dplOut_categorical_accuracy: 0.90470.986614\n",
      "349/349 [==============================] - 252s - loss: 9.7191 - lplOut_loss: 0.5613 - dplOut_loss: 0.2496 - lplOut_categorical_accuracy: 0.7844 - dplOut_categorical_accuracy: 0.9049 - val_loss: 11.4852 - val_lplOut_loss: 2.8130 - val_dplOut_loss: 0.2643 - val_lplOut_categorical_accuracy: 0.2859 - val_dplOut_categorical_accuracy: 0.8956\n",
      "Epoch 6/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 8.8129 - lplOut_loss: 0.5448 - dplOut_loss: 0.2841 - lplOut_categorical_accuracy: 0.7931 - dplOut_categorical_accuracy: 0.89020.995055\n",
      "349/349 [==============================] - 251s - loss: 8.8117 - lplOut_loss: 0.5449 - dplOut_loss: 0.2839 - lplOut_categorical_accuracy: 0.7929 - dplOut_categorical_accuracy: 0.8904 - val_loss: 10.7914 - val_lplOut_loss: 2.8754 - val_dplOut_loss: 0.3344 - val_lplOut_categorical_accuracy: 0.2869 - val_dplOut_categorical_accuracy: 0.8633\n",
      "Epoch 7/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 8.0705 - lplOut_loss: 0.5347 - dplOut_loss: 0.3112 - lplOut_categorical_accuracy: 0.7983 - dplOut_categorical_accuracy: 0.88360.998178\n",
      "349/349 [==============================] - 251s - loss: 8.0689 - lplOut_loss: 0.5344 - dplOut_loss: 0.3109 - lplOut_categorical_accuracy: 0.7984 - dplOut_categorical_accuracy: 0.8837 - val_loss: 10.1068 - val_lplOut_loss: 2.8663 - val_dplOut_loss: 0.3607 - val_lplOut_categorical_accuracy: 0.2972 - val_dplOut_categorical_accuracy: 0.8434\n",
      "Epoch 8/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 7.4352 - lplOut_loss: 0.5231 - dplOut_loss: 0.3464 - lplOut_categorical_accuracy: 0.8039 - dplOut_categorical_accuracy: 0.86720.999329\n",
      "349/349 [==============================] - 252s - loss: 7.4346 - lplOut_loss: 0.5232 - dplOut_loss: 0.3465 - lplOut_categorical_accuracy: 0.8039 - dplOut_categorical_accuracy: 0.8672 - val_loss: 9.5288 - val_lplOut_loss: 2.9117 - val_dplOut_loss: 0.3572 - val_lplOut_categorical_accuracy: 0.2827 - val_dplOut_categorical_accuracy: 0.8633\n",
      "Epoch 9/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 6.8784 - lplOut_loss: 0.5138 - dplOut_loss: 0.3866 - lplOut_categorical_accuracy: 0.8055 - dplOut_categorical_accuracy: 0.85390.999753\n",
      "349/349 [==============================] - 251s - loss: 6.8777 - lplOut_loss: 0.5137 - dplOut_loss: 0.3867 - lplOut_categorical_accuracy: 0.8054 - dplOut_categorical_accuracy: 0.8538 - val_loss: 8.8288 - val_lplOut_loss: 2.7682 - val_dplOut_loss: 0.3589 - val_lplOut_categorical_accuracy: 0.2908 - val_dplOut_categorical_accuracy: 0.8903\n",
      "Epoch 10/10\n",
      "348/349 [============================>.] - ETA: 0s - loss: 6.3708 - lplOut_loss: 0.5105 - dplOut_loss: 0.4174 - lplOut_categorical_accuracy: 0.8088 - dplOut_categorical_accuracy: 0.83910.999909\n",
      "349/349 [==============================] - 251s - loss: 6.3700 - lplOut_loss: 0.5104 - dplOut_loss: 0.4175 - lplOut_categorical_accuracy: 0.8088 - dplOut_categorical_accuracy: 0.8392 - val_loss: 8.4134 - val_lplOut_loss: 2.8034 - val_dplOut_loss: 0.4220 - val_lplOut_categorical_accuracy: 0.2855 - val_dplOut_categorical_accuracy: 0.8441\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "288/288 [==============================] - 103s - loss: 11.9519 - categorical_accuracy: 0.2653 - val_loss: 10.7454 - val_categorical_accuracy: 0.2780\n",
      "Epoch 2/10\n",
      "288/288 [==============================] - 103s - loss: 9.8246 - categorical_accuracy: 0.2858 - val_loss: 9.0450 - val_categorical_accuracy: 0.2746\n",
      "Epoch 3/10\n",
      "288/288 [==============================] - 103s - loss: 8.3988 - categorical_accuracy: 0.2896 - val_loss: 7.8754 - val_categorical_accuracy: 0.2880\n",
      "Epoch 4/10\n",
      "288/288 [==============================] - 103s - loss: 7.4000 - categorical_accuracy: 0.3071 - val_loss: 7.0488 - val_categorical_accuracy: 0.3072\n",
      "Epoch 5/10\n",
      "288/288 [==============================] - 103s - loss: 6.6727 - categorical_accuracy: 0.3265 - val_loss: 6.4521 - val_categorical_accuracy: 0.2900\n",
      "Epoch 6/10\n",
      "288/288 [==============================] - 103s - loss: 6.1283 - categorical_accuracy: 0.3334 - val_loss: 5.9785 - val_categorical_accuracy: 0.2995\n",
      "Epoch 7/10\n",
      "288/288 [==============================] - 103s - loss: 5.6982 - categorical_accuracy: 0.3376 - val_loss: 5.6234 - val_categorical_accuracy: 0.2856\n",
      "Epoch 8/10\n",
      "288/288 [==============================] - 103s - loss: 5.3355 - categorical_accuracy: 0.3587 - val_loss: 5.3029 - val_categorical_accuracy: 0.2950\n",
      "Epoch 9/10\n",
      "288/288 [==============================] - 103s - loss: 5.0241 - categorical_accuracy: 0.3624 - val_loss: 5.0637 - val_categorical_accuracy: 0.2809\n",
      "Epoch 10/10\n",
      "288/288 [==============================] - 103s - loss: 4.7509 - categorical_accuracy: 0.3737 - val_loss: 4.8270 - val_categorical_accuracy: 0.2766\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "349/349 [==============================] - 128s - loss: 11.2357 - categorical_accuracy: 0.5458 - val_loss: 9.5465 - val_categorical_accuracy: 0.7527\n",
      "Epoch 2/10\n",
      "349/349 [==============================] - 126s - loss: 8.7007 - categorical_accuracy: 0.7388 - val_loss: 7.9482 - val_categorical_accuracy: 0.7736\n",
      "Epoch 3/10\n",
      "349/349 [==============================] - 126s - loss: 7.4051 - categorical_accuracy: 0.7675 - val_loss: 6.9485 - val_categorical_accuracy: 0.7964\n",
      "Epoch 4/10\n",
      "349/349 [==============================] - 126s - loss: 6.5672 - categorical_accuracy: 0.7847 - val_loss: 6.2958 - val_categorical_accuracy: 0.7896\n",
      "Epoch 5/10\n",
      "349/349 [==============================] - 126s - loss: 5.9546 - categorical_accuracy: 0.7981 - val_loss: 5.7327 - val_categorical_accuracy: 0.8014\n",
      "Epoch 6/10\n",
      "349/349 [==============================] - 126s - loss: 5.4680 - categorical_accuracy: 0.8059 - val_loss: 5.3312 - val_categorical_accuracy: 0.8045\n",
      "Epoch 7/10\n",
      "349/349 [==============================] - 126s - loss: 5.0520 - categorical_accuracy: 0.8139 - val_loss: 4.9668 - val_categorical_accuracy: 0.7937\n",
      "Epoch 8/10\n",
      "349/349 [==============================] - 126s - loss: 4.6961 - categorical_accuracy: 0.8202 - val_loss: 4.6334 - val_categorical_accuracy: 0.8021\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349/349 [==============================] - 126s - loss: 4.3660 - categorical_accuracy: 0.8265 - val_loss: 4.3316 - val_categorical_accuracy: 0.8021\n",
      "Epoch 10/10\n",
      "349/349 [==============================] - 126s - loss: 4.0682 - categorical_accuracy: 0.8312 - val_loss: 4.0338 - val_categorical_accuracy: 0.8106\n",
      "Found 21643 images belonging to 5 classes.\n",
      "Found 18527 images belonging to 5 classes.\n",
      "Found 3637 images belonging to 5 classes.\n",
      "Found 1975 images belonging to 5 classes.\n",
      "Found 3042 images belonging to 5 classes.\n",
      "Found 2342 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n",
      "Epoch 1/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 21.2134 - lplOut_loss: 1.1382 - dplOut_loss: 0.2618 - lplOut_categorical_accuracy: 0.5433 - dplOut_categorical_accuracy: 0.91180.462117\n",
      "338/338 [==============================] - 253s - loss: 21.2033 - lplOut_loss: 1.1373 - dplOut_loss: 0.2613 - lplOut_categorical_accuracy: 0.5437 - dplOut_categorical_accuracy: 0.9120 - val_loss: 19.5639 - val_lplOut_loss: 2.5634 - val_dplOut_loss: 0.1626 - val_lplOut_categorical_accuracy: 0.2631 - val_dplOut_categorical_accuracy: 0.9422\n",
      "Epoch 2/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 15.6745 - lplOut_loss: 0.6639 - dplOut_loss: 0.1205 - lplOut_categorical_accuracy: 0.7536 - dplOut_categorical_accuracy: 0.95730.761594\n",
      "338/338 [==============================] - 251s - loss: 15.6693 - lplOut_loss: 0.6637 - dplOut_loss: 0.1204 - lplOut_categorical_accuracy: 0.7537 - dplOut_categorical_accuracy: 0.9574 - val_loss: 16.1998 - val_lplOut_loss: 2.8132 - val_dplOut_loss: 0.1421 - val_lplOut_categorical_accuracy: 0.2723 - val_dplOut_categorical_accuracy: 0.9503\n",
      "Epoch 3/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 12.7548 - lplOut_loss: 0.5814 - dplOut_loss: 0.1116 - lplOut_categorical_accuracy: 0.7812 - dplOut_categorical_accuracy: 0.96290.905148\n",
      "338/338 [==============================] - 252s - loss: 12.7520 - lplOut_loss: 0.5815 - dplOut_loss: 0.1117 - lplOut_categorical_accuracy: 0.7810 - dplOut_categorical_accuracy: 0.9628 - val_loss: 14.0741 - val_lplOut_loss: 2.8939 - val_dplOut_loss: 0.1552 - val_lplOut_categorical_accuracy: 0.2732 - val_dplOut_categorical_accuracy: 0.9473\n",
      "Epoch 4/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 10.9403 - lplOut_loss: 0.5368 - dplOut_loss: 0.1629 - lplOut_categorical_accuracy: 0.7985 - dplOut_categorical_accuracy: 0.94070.964028\n",
      "338/338 [==============================] - 252s - loss: 10.9388 - lplOut_loss: 0.5370 - dplOut_loss: 0.1632 - lplOut_categorical_accuracy: 0.7984 - dplOut_categorical_accuracy: 0.9405 - val_loss: 12.7408 - val_lplOut_loss: 2.9909 - val_dplOut_loss: 0.2083 - val_lplOut_categorical_accuracy: 0.2732 - val_dplOut_categorical_accuracy: 0.9213\n",
      "Epoch 5/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 9.7483 - lplOut_loss: 0.5219 - dplOut_loss: 0.2332 - lplOut_categorical_accuracy: 0.8063 - dplOut_categorical_accuracy: 0.91200.986614\n",
      "338/338 [==============================] - 253s - loss: 9.7464 - lplOut_loss: 0.5217 - dplOut_loss: 0.2330 - lplOut_categorical_accuracy: 0.8064 - dplOut_categorical_accuracy: 0.9121 - val_loss: 11.6540 - val_lplOut_loss: 2.9188 - val_dplOut_loss: 0.2449 - val_lplOut_categorical_accuracy: 0.2807 - val_dplOut_categorical_accuracy: 0.9180\n",
      "Epoch 6/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 8.8195 - lplOut_loss: 0.5056 - dplOut_loss: 0.2495 - lplOut_categorical_accuracy: 0.8102 - dplOut_categorical_accuracy: 0.91040.995055\n",
      "338/338 [==============================] - 252s - loss: 8.8183 - lplOut_loss: 0.5053 - dplOut_loss: 0.2498 - lplOut_categorical_accuracy: 0.8102 - dplOut_categorical_accuracy: 0.9104 - val_loss: 10.8003 - val_lplOut_loss: 2.8838 - val_dplOut_loss: 0.2567 - val_lplOut_categorical_accuracy: 0.2835 - val_dplOut_categorical_accuracy: 0.9188\n",
      "Epoch 7/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 8.0941 - lplOut_loss: 0.5018 - dplOut_loss: 0.2906 - lplOut_categorical_accuracy: 0.8115 - dplOut_categorical_accuracy: 0.89490.998178\n",
      "338/338 [==============================] - 252s - loss: 8.0943 - lplOut_loss: 0.5027 - dplOut_loss: 0.2909 - lplOut_categorical_accuracy: 0.8111 - dplOut_categorical_accuracy: 0.8947 - val_loss: 10.0516 - val_lplOut_loss: 2.8027 - val_dplOut_loss: 0.2935 - val_lplOut_categorical_accuracy: 0.2796 - val_dplOut_categorical_accuracy: 0.8945\n",
      "Epoch 8/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 7.4722 - lplOut_loss: 0.4954 - dplOut_loss: 0.3364 - lplOut_categorical_accuracy: 0.8150 - dplOut_categorical_accuracy: 0.87790.999329\n",
      "338/338 [==============================] - 252s - loss: 7.4718 - lplOut_loss: 0.4957 - dplOut_loss: 0.3366 - lplOut_categorical_accuracy: 0.8150 - dplOut_categorical_accuracy: 0.8778 - val_loss: 9.3770 - val_lplOut_loss: 2.7202 - val_dplOut_loss: 0.3238 - val_lplOut_categorical_accuracy: 0.2902 - val_dplOut_categorical_accuracy: 0.9009\n",
      "Epoch 9/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 6.9326 - lplOut_loss: 0.4924 - dplOut_loss: 0.3908 - lplOut_categorical_accuracy: 0.8173 - dplOut_categorical_accuracy: 0.85800.999753\n",
      "338/338 [==============================] - 252s - loss: 6.9321 - lplOut_loss: 0.4926 - dplOut_loss: 0.3909 - lplOut_categorical_accuracy: 0.8172 - dplOut_categorical_accuracy: 0.8581 - val_loss: 8.9163 - val_lplOut_loss: 2.7548 - val_dplOut_loss: 0.3918 - val_lplOut_categorical_accuracy: 0.2857 - val_dplOut_categorical_accuracy: 0.8597\n",
      "Epoch 10/10\n",
      "337/338 [============================>.] - ETA: 0s - loss: 6.4366 - lplOut_loss: 0.4875 - dplOut_loss: 0.4408 - lplOut_categorical_accuracy: 0.8203 - dplOut_categorical_accuracy: 0.83500.999909\n",
      "338/338 [==============================] - 252s - loss: 6.4360 - lplOut_loss: 0.4877 - dplOut_loss: 0.4407 - lplOut_categorical_accuracy: 0.8202 - dplOut_categorical_accuracy: 0.8349 - val_loss: 8.4986 - val_lplOut_loss: 2.8055 - val_dplOut_loss: 0.4417 - val_lplOut_categorical_accuracy: 0.2818 - val_dplOut_categorical_accuracy: 0.8510\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 104s - loss: 11.9595 - categorical_accuracy: 0.2666 - val_loss: 10.7306 - val_categorical_accuracy: 0.3098\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 102s - loss: 9.8266 - categorical_accuracy: 0.2936 - val_loss: 9.0716 - val_categorical_accuracy: 0.2564\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 102s - loss: 8.4103 - categorical_accuracy: 0.3110 - val_loss: 7.9020 - val_categorical_accuracy: 0.2742\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 102s - loss: 7.4204 - categorical_accuracy: 0.3222 - val_loss: 7.0883 - val_categorical_accuracy: 0.2732\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 102s - loss: 6.6955 - categorical_accuracy: 0.3407 - val_loss: 6.4817 - val_categorical_accuracy: 0.2381\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 102s - loss: 6.1542 - categorical_accuracy: 0.3412 - val_loss: 6.0106 - val_categorical_accuracy: 0.2527\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 102s - loss: 5.7035 - categorical_accuracy: 0.3525 - val_loss: 5.6038 - val_categorical_accuracy: 0.2883\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 102s - loss: 5.3397 - categorical_accuracy: 0.3577 - val_loss: 5.2987 - val_categorical_accuracy: 0.2386\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 102s - loss: 5.0088 - categorical_accuracy: 0.3756 - val_loss: 5.0075 - val_categorical_accuracy: 0.2742\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 102s - loss: 4.7287 - categorical_accuracy: 0.3800 - val_loss: 4.7697 - val_categorical_accuracy: 0.2459\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "preLp (Flatten)              (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "preDnsDo (Dropout)           (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "lpl1 (Dense)                 (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "lpl1Do (Dropout)             (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "lpl2 (Dense)                 (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "lplOut (Dense)               (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 27,825,477\n",
      "Trainable params: 15,470,597\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "338/338 [==============================] - 127s - loss: 11.2600 - categorical_accuracy: 0.5587 - val_loss: 9.4371 - val_categorical_accuracy: 0.8049\n",
      "Epoch 2/10\n",
      "338/338 [==============================] - 126s - loss: 8.7319 - categorical_accuracy: 0.7555 - val_loss: 7.8928 - val_categorical_accuracy: 0.8156\n",
      "Epoch 3/10\n",
      "338/338 [==============================] - 126s - loss: 7.4519 - categorical_accuracy: 0.7850 - val_loss: 6.9182 - val_categorical_accuracy: 0.8136\n",
      "Epoch 4/10\n",
      "338/338 [==============================] - 126s - loss: 6.6208 - categorical_accuracy: 0.7998 - val_loss: 6.2519 - val_categorical_accuracy: 0.8192\n",
      "Epoch 5/10\n",
      "338/338 [==============================] - 126s - loss: 6.0100 - categorical_accuracy: 0.8135 - val_loss: 5.7382 - val_categorical_accuracy: 0.8217\n",
      "Epoch 6/10\n",
      "338/338 [==============================] - 126s - loss: 5.5312 - categorical_accuracy: 0.8189 - val_loss: 5.3425 - val_categorical_accuracy: 0.8147\n",
      "Epoch 7/10\n",
      "338/338 [==============================] - 126s - loss: 5.1200 - categorical_accuracy: 0.8293 - val_loss: 4.9832 - val_categorical_accuracy: 0.8035\n",
      "Epoch 8/10\n",
      "338/338 [==============================] - 126s - loss: 4.7576 - categorical_accuracy: 0.8372 - val_loss: 4.6635 - val_categorical_accuracy: 0.8074\n",
      "Epoch 9/10\n",
      "338/338 [==============================] - 126s - loss: 4.4369 - categorical_accuracy: 0.8385 - val_loss: 4.3450 - val_categorical_accuracy: 0.8074\n",
      "Epoch 10/10\n",
      "338/338 [==============================] - 126s - loss: 4.1334 - categorical_accuracy: 0.8445 - val_loss: 4.0590 - val_categorical_accuracy: 0.8130\n",
      "Found 22644 images belonging to 5 classes.\n",
      "Found 20128 images belonging to 5 classes.\n",
      "Found 2173 images belonging to 5 classes.\n",
      "Found 2716 images belonging to 5 classes.\n",
      "Found 3505 images belonging to 5 classes.\n",
      "Found 0 images belonging to 5 classes.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl_vgg_outDo (Dropout)          (None, 25088)         0           model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 512)           12845568    lpl_vgg_outDo[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 512)           12845568    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 512)           0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 512)           0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 512)           262656      lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 512)           262656      dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             2565        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             1026        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 40,934,727\n",
      "Trainable params: 28,579,847\n",
      "Non-trainable params: 12,354,880\n",
      "____________________________________________________________________________________________________\n",
      "0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 21.0215 - lplOut_loss: 1.0621 - dplOut_loss: 0.2731 - lplOut_categorical_accuracy: 0.5763 - dplOut_categorical_accuracy: 0.90660.462117\n",
      "353/353 [==============================] - 250s - loss: 21.0115 - lplOut_loss: 1.0612 - dplOut_loss: 0.2727 - lplOut_categorical_accuracy: 0.5768 - dplOut_categorical_accuracy: 0.9067 - val_loss: 19.0503 - val_lplOut_loss: 2.2728 - val_dplOut_loss: 0.1271 - val_lplOut_categorical_accuracy: 0.3982 - val_dplOut_categorical_accuracy: 0.9702\n",
      "Epoch 2/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 15.4532 - lplOut_loss: 0.6399 - dplOut_loss: 0.1344 - lplOut_categorical_accuracy: 0.7614 - dplOut_categorical_accuracy: 0.95170.761594\n",
      "353/353 [==============================] - 249s - loss: 15.4485 - lplOut_loss: 0.6399 - dplOut_loss: 0.1344 - lplOut_categorical_accuracy: 0.7615 - dplOut_categorical_accuracy: 0.9516 - val_loss: 15.6730 - val_lplOut_loss: 2.5133 - val_dplOut_loss: 0.1423 - val_lplOut_categorical_accuracy: 0.4167 - val_dplOut_categorical_accuracy: 0.9555\n",
      "Epoch 3/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 12.5316 - lplOut_loss: 0.5713 - dplOut_loss: 0.1280 - lplOut_categorical_accuracy: 0.7880 - dplOut_categorical_accuracy: 0.95540.905148\n",
      "353/353 [==============================] - 248s - loss: 12.5287 - lplOut_loss: 0.5713 - dplOut_loss: 0.1280 - lplOut_categorical_accuracy: 0.7880 - dplOut_categorical_accuracy: 0.9554 - val_loss: 13.5467 - val_lplOut_loss: 2.6075 - val_dplOut_loss: 0.1418 - val_lplOut_categorical_accuracy: 0.4190 - val_dplOut_categorical_accuracy: 0.9631\n",
      "Epoch 4/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 10.7286 - lplOut_loss: 0.5359 - dplOut_loss: 0.1760 - lplOut_categorical_accuracy: 0.8018 - dplOut_categorical_accuracy: 0.93650.964028\n",
      "353/353 [==============================] - 248s - loss: 10.7266 - lplOut_loss: 0.5355 - dplOut_loss: 0.1763 - lplOut_categorical_accuracy: 0.8020 - dplOut_categorical_accuracy: 0.9363 - val_loss: 12.2897 - val_lplOut_loss: 2.7059 - val_dplOut_loss: 0.2623 - val_lplOut_categorical_accuracy: 0.4072 - val_dplOut_categorical_accuracy: 0.8868\n",
      "Epoch 5/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 9.5577 - lplOut_loss: 0.5198 - dplOut_loss: 0.2652 - lplOut_categorical_accuracy: 0.8037 - dplOut_categorical_accuracy: 0.89680.986614\n",
      "353/353 [==============================] - 248s - loss: 9.5566 - lplOut_loss: 0.5201 - dplOut_loss: 0.2652 - lplOut_categorical_accuracy: 0.8037 - dplOut_categorical_accuracy: 0.8969 - val_loss: 11.1996 - val_lplOut_loss: 2.7251 - val_dplOut_loss: 0.2064 - val_lplOut_categorical_accuracy: 0.4242 - val_dplOut_categorical_accuracy: 0.9375\n",
      "Epoch 6/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 8.6139 - lplOut_loss: 0.5063 - dplOut_loss: 0.2678 - lplOut_categorical_accuracy: 0.8111 - dplOut_categorical_accuracy: 0.90310.995055\n",
      "353/353 [==============================] - 248s - loss: 8.6129 - lplOut_loss: 0.5063 - dplOut_loss: 0.2679 - lplOut_categorical_accuracy: 0.8111 - dplOut_categorical_accuracy: 0.9030 - val_loss: 10.4620 - val_lplOut_loss: 2.7561 - val_dplOut_loss: 0.2726 - val_lplOut_categorical_accuracy: 0.4148 - val_dplOut_categorical_accuracy: 0.9124\n",
      "Epoch 7/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 7.8912 - lplOut_loss: 0.4994 - dplOut_loss: 0.3190 - lplOut_categorical_accuracy: 0.8142 - dplOut_categorical_accuracy: 0.88010.998178\n",
      "353/353 [==============================] - 249s - loss: 7.8901 - lplOut_loss: 0.4994 - dplOut_loss: 0.3189 - lplOut_categorical_accuracy: 0.8142 - dplOut_categorical_accuracy: 0.8803 - val_loss: 9.6913 - val_lplOut_loss: 2.6057 - val_dplOut_loss: 0.3610 - val_lplOut_categorical_accuracy: 0.4389 - val_dplOut_categorical_accuracy: 0.8343\n",
      "Epoch 8/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 7.2670 - lplOut_loss: 0.4899 - dplOut_loss: 0.3708 - lplOut_categorical_accuracy: 0.8202 - dplOut_categorical_accuracy: 0.86020.999329\n",
      "353/353 [==============================] - 248s - loss: 7.2661 - lplOut_loss: 0.4900 - dplOut_loss: 0.3707 - lplOut_categorical_accuracy: 0.8202 - dplOut_categorical_accuracy: 0.8604 - val_loss: 9.1627 - val_lplOut_loss: 2.6754 - val_dplOut_loss: 0.3914 - val_lplOut_categorical_accuracy: 0.4129 - val_dplOut_categorical_accuracy: 0.8404\n",
      "Epoch 9/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 6.7195 - lplOut_loss: 0.4953 - dplOut_loss: 0.4163 - lplOut_categorical_accuracy: 0.8184 - dplOut_categorical_accuracy: 0.84190.999753\n",
      "353/353 [==============================] - 249s - loss: 6.7186 - lplOut_loss: 0.4951 - dplOut_loss: 0.4163 - lplOut_categorical_accuracy: 0.8184 - dplOut_categorical_accuracy: 0.8418 - val_loss: 8.6511 - val_lplOut_loss: 2.6952 - val_dplOut_loss: 0.4298 - val_lplOut_categorical_accuracy: 0.4110 - val_dplOut_categorical_accuracy: 0.8068\n",
      "Epoch 10/10\n",
      "352/353 [============================>.] - ETA: 0s - loss: 6.2060 - lplOut_loss: 0.4855 - dplOut_loss: 0.4567 - lplOut_categorical_accuracy: 0.8233 - dplOut_categorical_accuracy: 0.82000.999909\n",
      "353/353 [==============================] - 248s - loss: 6.2052 - lplOut_loss: 0.4852 - dplOut_loss: 0.4569 - lplOut_categorical_accuracy: 0.8234 - dplOut_categorical_accuracy: 0.8200 - val_loss: 8.1917 - val_lplOut_loss: 2.6538 - val_dplOut_loss: 0.5329 - val_lplOut_categorical_accuracy: 0.4200 - val_dplOut_categorical_accuracy: 0.7325\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-764662c7c5b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Physionet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hospital'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mtest_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_lable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDTD_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdom\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDTD_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdom\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mtmp_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_lable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDTD_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdom\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \"\"\"\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0mindex_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m_flow_index\u001b[0;34m(self, n, batch_size, shuffle, seed)\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             \u001b[0mcurrent_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mcurrent_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "for phys_split, hosp_split in zip(kf.split(n_subjects_phys),kf.split(n_subjects_hosp)):\n",
    "\n",
    "    # memory management\n",
    "    this = sys.modules[__name__]\n",
    "    for n in dir():\n",
    "        if n not in whitelist: delattr(this, n)\n",
    "    K.clear_session()\n",
    "\n",
    "    #Define current time\n",
    "    now = datetime.now()\n",
    "    #print(\"PHYS:\\n\" + \"Train:\" + str(phys_split[0]) + '\\n' + 'Test:' + str(phys_split[1]) + \"\\n\")\n",
    "    #print(\"Hosp:\\n\" + \"Train:\" + str(hosp_split[0]) + '\\n' + 'Test:' + str(hosp_split[1]) + \"\\n\")\n",
    "    \n",
    "    reverse_data_split(source_data)\n",
    "    reverse_data_split(target_data)\n",
    "    \n",
    "    #Data split for physionet\n",
    "    create_data_split(source_data,phys_split[1]+1)\n",
    "    #Data split for target\n",
    "    create_data_split(target_data,hosp_split[1]+1)\n",
    "    \n",
    "    \n",
    "    #### Train data\n",
    "\n",
    "\n",
    "    train_gen_source = datagen.flow_from_directory(source_data + '/train', target_size=(224, 224), \n",
    "                                                   batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "    train_gen_target = datagen.flow_from_directory(target_data + '/train', target_size=(224, 224), \n",
    "                                                   batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "    train_gen_DA = train_gen_DAnet(train_gen_source, train_gen_target, batch_size)\n",
    "\n",
    "    train_stepE = np.floor_divide(train_gen_source.n, batch_size)\n",
    "    train_stepE_target = np.floor_divide(train_gen_target.n, batch_size)\n",
    "    #### validation data\n",
    "\n",
    "    valid_gen_source = datagen.flow_from_directory(source_data + '/validation', target_size=(224, 224), \n",
    "                                                   batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "    valid_gen_target = datagen.flow_from_directory(target_data + '/validation', target_size=(224, 224), \n",
    "                                                   batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "    valid_gen_DA = test_gen_DAnet(valid_gen_source, valid_gen_target, batch_size)\n",
    "\n",
    "    valid_stepE = np.floor_divide(valid_gen_source.n, batch_size)\n",
    "    valid_stepE_target = np.floor_divide(valid_gen_target.n, batch_size)\n",
    "\n",
    "    #### test data\n",
    "\n",
    "    test_gen_source = datagen.flow_from_directory(source_data + '/test', target_size=(224, 224), \n",
    "                                                   batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "    test_gen_target = datagen.flow_from_directory(target_data + '/test', target_size=(224, 224), \n",
    "                                                   batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "    test_gen_DA = test_gen_DAnet(test_gen_source, test_gen_target, batch_size)\n",
    "\n",
    "    test_stepE = np.floor_divide(test_gen_source.n, batch_size)\n",
    "    test_stepE_target = np.floor_divide(test_gen_target.n, batch_size)   \n",
    "    \n",
    "    \n",
    "    #Define lamFunk\n",
    "    lamFunk = K.variable(0.0)\n",
    "    \n",
    "    for item in MIQ:\n",
    "        if item==\"DA\":         \n",
    "            current_model = Models.DA_model(lamFunk,do_rate_dpl=0, do_rate_lpl=0.5, vgg_train=False, nrUnits=[512,512])\n",
    "        else:\n",
    "            current_model = Models.lable_model(do_rate=0.5, vgg_train=False, nrUnits=[512,512])\n",
    "        \n",
    "        csv_logger = CSVLogger('/media/jaskmo/ELEK/bme/Project02456/trainingLog/' + item + \n",
    "                        str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                        str(now.hour) + str(now.minute) + '.log')\n",
    "        if item=='DA':\n",
    "            current_model.fit_generator(train_gen_DA, train_stepE, epochs=nrEpochs, verbose=1, validation_data=valid_gen_DA, \n",
    "                            validation_steps=valid_stepE, callbacks=[csv_logger,FlipControle(lamFunk)], initial_epoch=0,\n",
    "                            max_queue_size=5, class_weight = {'lplOut':[1,0.33,0.33,0.33,0.5],'dplOut':[1,1]})\n",
    "        elif item=='source':\n",
    "            current_model.fit_generator(train_gen_source, train_stepE, epochs=nrEpochs, verbose=1, validation_data=valid_gen_source, \n",
    "                            validation_steps=valid_stepE, callbacks=[csv_logger], initial_epoch=0,\n",
    "                            max_queue_size=5, class_weight = [1,0.33,0.33,0.33,0.5])\n",
    "        else:\n",
    "            current_model.fit_generator(train_gen_target, train_stepE_target, epochs=nrEpochs, verbose=1, validation_data=valid_gen_target, \n",
    "                            validation_steps=valid_stepE_target, callbacks=[csv_logger], initial_epoch=0,\n",
    "                            max_queue_size=5, class_weight = [1,0.33,0.33,0.33,0.5])\n",
    "                     \n",
    "        if item == \"DA\":\n",
    "            DAlpm = utils.dissect_DAlpm(current_model)\n",
    "            current_model = DAlpm\n",
    "            \n",
    "#         #Save the model\n",
    "#         current_model.save(filepath=path + 'models/'+ item + str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "#                        str(now.hour) + str(now.minute) + '.h5')\n",
    "        \n",
    "        #TEST\n",
    "        DTD_dic = {'Physionet':test_gen_source,'Hospital':test_gen_target}\n",
    "        # save to file \n",
    "        test_file = '/media/jaskmo/ELEK/bme/Project02456/testLog/'+ item + str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + str(now.hour) + str(now.minute) + '.log'\n",
    "        sys.stdout = open(test_file, 'w')\n",
    "        \n",
    "        for dom in ['Physionet', 'Hospital']:\n",
    "            test_img, test_lable = DTD_dic[dom].next()\n",
    "            for count in range(DTD_dic[dom].n//batch_size):\n",
    "                tmp_img, tmp_lable = DTD_dic[dom].next()\n",
    "                test_img = np.concatenate((test_img, tmp_img), axis=0)\n",
    "                test_lable = np.concatenate((test_lable, tmp_lable),axis=0)\n",
    "\n",
    "            # Compute the test metrecis \n",
    "            inv_map = {v: k for k, v in DTD_dic[dom].class_indices.items()}\n",
    "            target_names = list(inv_map.values())\n",
    "\n",
    "            targets_test_int = [np.where(r == 1)[0][0] for r in test_lable]\n",
    "            y_pred = current_model.predict(test_img)\n",
    "            y_pred2 = np.argmax(y_pred, axis = 1)\n",
    "            # Test accuracy:\n",
    "            acc = accuracy_score(targets_test_int, y_pred2)\n",
    "            \n",
    "            conf_mat = confusion_matrix(targets_test_int, y_pred2)\n",
    "            # Per class metrics\n",
    "            class_report = classification_report(targets_test_int, y_pred2, target_names=target_names)\n",
    "\n",
    "            print('Accuracy on ' + dom + ' data = ' + str(acc) +'\\n \\n' + \n",
    "                  'Confution matric on ' + dom + ' data: \\n' + str(conf_mat) + '\\n\\n' + \n",
    "                  'Class report on ' + dom + ' data: \\n' + class_report + '\\n\\n\\n\\n')\n",
    "\n",
    "        sys.stdout = stdout_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
