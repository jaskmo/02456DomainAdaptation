{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, Callback\n",
    "from datetime import datetime\n",
    "import keras.backend as K\n",
    "import extras.ourUtils as utils\n",
    "import numpy as np\n",
    "import Models\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "nrEpochs = 10\n",
    "full_train = True\n",
    "path = '/home/jaskmo/Documents/programering/02456DomainAdaptation/'\n",
    "source_data = path + 'taperImages/pysNetData'\n",
    "target_data = path + 'taperImages/hData'\n",
    "stdout_cell = sys.stdout\n",
    "MIQ = ['DA', 'target', 'source']\n",
    "kf = KFold(n_splits = 10)\n",
    "n_subjects_phys = np.arange(1,21);\n",
    "n_subjects_hosp = np.arange(1,38);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data as generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# make a data generator for dplInput\n",
    "def train_gen_DAnet(source, target, batch_size):\n",
    "    half = batch_size//2\n",
    "    while True:\n",
    "        source_data, source_lable = source.next()\n",
    "        target_data, target_lable = target.next()\n",
    "        if len(source_lable) != batch_size or len(target_lable) != batch_size:\n",
    "            continue\n",
    "        dpl_data = np.concatenate((source_data[:half,...],target_data[:half,...]),axis=0)\n",
    "               \n",
    "        domain_tmp = np.ones(batch_size, dtype='int8')\n",
    "        domain_tmp[half:] = domain_tmp[half:] * 0\n",
    "        dpl_lable = np.concatenate((domain_tmp.reshape(batch_size,1),\n",
    "                                       np.flip(domain_tmp,0).reshape(batch_size,1)),1)\n",
    "\n",
    "        yield({'lplInput':source_data,'dplInput':dpl_data}, {'lplOut':source_lable,'dplOut':dpl_lable})\n",
    "        \n",
    "def test_gen_DAnet(source, target, batch_size):\n",
    "    half = batch_size//2\n",
    "    while True:\n",
    "        source_data, source_lable = source.next()\n",
    "        target_data, target_lable = target.next()\n",
    "        if len(source_lable) != batch_size or len(target_lable) != batch_size:\n",
    "            continue\n",
    "        dpl_data = np.concatenate((source_data[:half,...],target_data[:half,...]),axis=0)\n",
    "               \n",
    "        domain_tmp = np.ones(batch_size, dtype='int8')\n",
    "        domain_tmp[half:] = domain_tmp[half:] * 0\n",
    "        dpl_lable = np.concatenate((domain_tmp.reshape(batch_size,1),\n",
    "                                       np.flip(domain_tmp,0).reshape(batch_size,1)),1)\n",
    "\n",
    "        yield({'lplInput':target_data,'dplInput':dpl_data}, {'lplOut':target_lable,'dplOut':dpl_lable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHYS:\n",
      "Train:[ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "Test:[0 1]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36]\n",
      "Test:[0 1 2 3]\n",
      "\n",
      "PHYS:\n",
      "Train:[ 0  1  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "Test:[2 3]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 0  1  2  3  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36]\n",
      "Test:[4 5 6 7]\n",
      "\n",
      "PHYS:\n",
      "Train:[ 0  1  2  3  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "Test:[4 5]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 0  1  2  3  4  5  6  7 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36]\n",
      "Test:[ 8  9 10 11]\n",
      "\n",
      "PHYS:\n",
      "Train:[ 0  1  2  3  4  5  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "Test:[6 7]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 16 17 18 19 20 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36]\n",
      "Test:[12 13 14 15]\n",
      "\n",
      "PHYS:\n",
      "Train:[ 0  1  2  3  4  5  6  7 10 11 12 13 14 15 16 17 18 19]\n",
      "Test:[8 9]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 20 21 22 23 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36]\n",
      "Test:[16 17 18 19]\n",
      "\n",
      "PHYS:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 12 13 14 15 16 17 18 19]\n",
      "Test:[10 11]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 24 25 26 27 28\n",
      " 29 30 31 32 33 34 35 36]\n",
      "Test:[20 21 22 23]\n",
      "\n",
      "PHYS:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 14 15 16 17 18 19]\n",
      "Test:[12 13]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 28\n",
      " 29 30 31 32 33 34 35 36]\n",
      "Test:[24 25 26 27]\n",
      "\n",
      "PHYS:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 16 17 18 19]\n",
      "Test:[14 15]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 31 32 33 34 35 36]\n",
      "Test:[28 29 30]\n",
      "\n",
      "PHYS:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 18 19]\n",
      "Test:[16 17]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 34 35 36]\n",
      "Test:[31 32 33]\n",
      "\n",
      "PHYS:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n",
      "Test:[18 19]\n",
      "\n",
      "Hosp:\n",
      "Train:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33]\n",
      "Test:[34 35 36]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for phys_split, hosp_split in zip(kf.split(n_subjects_phys),kf.split(n_subjects_hosp)):\n",
    "    print(\"PHYS:\\n\" + \"Train:\" + str(phys_split[0]) + '\\n' + 'Test:' + str(phys_split[1]) + \"\\n\")\n",
    "    print(\"Hosp:\\n\" + \"Train:\" + str(hosp_split[0]) + '\\n' + 'Test:' + str(hosp_split[1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for train_index_phys, test_index_phys, train_index_hosp, test_indx_host  in zip(kf.split(n_subjects_phys),kf.split(n_subjects_hosp)):\n",
    "        rev hos\n",
    "        rev phy\n",
    "        create_data_split(path, test_index)\n",
    "        create_data_split()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_gen_source = datagen.flow_from_directory(source_data + '/train', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "train_gen_target = datagen.flow_from_directory(target_data + '/train', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "train_gen_DA = train_gen_DAnet(train_gen_source, train_gen_target, batch_size)\n",
    "\n",
    "train_stepE = np.floor_divide(train_gen_source.n, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_gen_source = datagen.flow_from_directory(source_data + '/validation', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "valid_gen_target = datagen.flow_from_directory(target_data + '/validation', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "valid_gen_DA = test_gen_DAnet(valid_gen_source, valid_gen_target, batch_size)\n",
    "\n",
    "val_stepE = np.floor_divide(valid_gen_source.n, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_gen_source = datagen.flow_from_directory(source_data + '/test', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "test_gen_target = datagen.flow_from_directory(target_data + '/test', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "test_gen_DA = test_gen_DAnet(test_gen_source, test_gen_target, batch_size)\n",
    "\n",
    "test_stepE = np.floor_divide(test_gen_source.n, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init. the variable to controle the flipgradient layer\n",
    "lamFunk = K.variable(0.0)\n",
    "current_model = Models.DA_model(lamFunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "csv_logger = CSVLogger('/media/jaskmo/ELEK/bme/Project02456/trainingLog/DA_Model' + \n",
    "                           str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                           str(now.hour) + str(now.minute) + '.log')\n",
    "\n",
    "class FlipControle(Callback):\n",
    "    def __init__(self, alphaIn):\n",
    "        self.alpha = alphaIn\n",
    "        print(K.get_value(lamFunk))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        p = (epoch+1)/nrEpochs\n",
    "        K.set_value(self.alpha, (2/(1+np.exp(-10*p)))-1)\n",
    "        print(K.get_value(lamFunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the S!@¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_model.fit_generator(train_gen_DA, train_stepE, epochs=nrEpochs, verbose=1, validation_data=test_gen_DA, \n",
    "                            validation_steps=val_stepE, callbacks=[csv_logger,FlipControle(lamFunk)], initial_epoch=0,\n",
    "                            max_queue_size=2)\n",
    "\n",
    "if MIQ == \"DA\":\n",
    "    DAlpm = utils.dissect_DAlpm(current_model)\n",
    "    current_model = DAlpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "    \n",
    "current_model.save(filepath=path + 'models/'+ MIQ + str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                       str(now.hour) + str(now.minute) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img, test_lable = test_gen_target.next()\n",
    "for count in range(test_gen_target.n//batch_size):\n",
    "    tmp_img, tmp_lable = test_gen_target.next()\n",
    "    test_img = np.concatenate((test_img, tmp_img), axis=0)\n",
    "    test_lable = np.concatenate((test_lable, tmp_lable),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the test metrecis \n",
    "inv_map = {v: k for k, v in test_gen_target.class_indices.items()}\n",
    "target_names = list(inv_map.values())\n",
    "\n",
    "targets_test_int = [np.where(r == 1)[0][0] for r in test_lable]\n",
    "y_pred = mod.predict(test_img)\n",
    "y_pred2 = np.argmax(y_pred, axis = 1)\n",
    "# Test accuracy:\n",
    "acc = accuracy_score(targets_test_int, y_pred2)\n",
    "print('Accuracy on target domain = ', acc)\n",
    "\n",
    "conf_mat = confusion_matrix(targets_test_int, y_pred2)\n",
    "print(conf_mat)\n",
    "# Per class metrics\n",
    "class_report = classification_report(targets_test_int, y_pred2, target_names=target_names)\n",
    "print(class_report)\n",
    "\n",
    "# save to file \n",
    "test_file = '/media/jaskmo/ELEK/bme/Project02456/testLog/DA_Model' + str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + str(now.hour) + str(now.minute) + '.log'\n",
    "\n",
    "sys.stdout = open(test_file, 'w')\n",
    "\n",
    "print('Accuracy on target domain = ' + str(acc) +'\\n \\n' + \n",
    "      'Confution matric on target domain: \\n' + str(conf_mat) + '\\n\\n' + \n",
    "      'Class report on target domain: \\n' + class_report)\n",
    "\n",
    "sys.stdout = stdout_cell\n",
    "\n",
    "# Evaluate error on source data\n",
    "# _, metric = current_model.evaluate_generator(generator=test_gen_DA, steps=test_stepE)\n",
    "# print('Accuracy on source domain = ', metric)\n",
    "\n",
    "    \n",
    "# elif training_mode == 'target': # Training on target data from hospital\n",
    "#     # Convert from onehot\n",
    "#     targets_test_int = [np.where(r == 1)[0][0] for r in targets_test_hosp]\n",
    "#     y_pred = current_model.predict(inputs_test_hosp)\n",
    "#     y_pred2 = np.argmax(y_pred, axis = 1)\n",
    "#     # Test accuracy:\n",
    "#     acc = accuracy_score(targets_test_int, y_pred2)\n",
    "#     print('Accuracy in this domain = ', acc)\n",
    "#     # Confusion matrix for target\n",
    "#     conf_mat = confusion_matrix(targets_test_int, y_pred2)\n",
    "#     print(conf_mat)\n",
    "#     # Per class metrics\n",
    "#     class_report = classification_report(targets_test_int, y_pred2, target_names=target_names)\n",
    "#     print(class_report)\n",
    "    \n",
    "#     # Evaluate error on source data\n",
    "#     _, metric = current_model.evaluate(x=inputs_test_phys, y=targets_test_phys, batch_size=50)\n",
    "#     print('Accuracy on other domain = ', metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
