{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, Callback\n",
    "from datetime import datetime\n",
    "import keras.backend as K\n",
    "import extras.ourUtils as utils\n",
    "import numpy as np\n",
    "import Models\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklear.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "nrEpochs = 10\n",
    "full_train = True\n",
    "path = '/home/jaskmo/Documents/programering/02456DomainAdaptation/'\n",
    "source_data = path + 'taperImages/pysNetData'\n",
    "target_data = path + 'taperImages/hData'\n",
    "stdout_cell = sys.stdout\n",
    "MIQ = ['DA', 'target', 'source']\n",
    "kf = KFold(n_splits = 10)\n",
    "n_subjects_phys = 20;\n",
    "n_subjects_hosp = 37;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data as generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# make a data generator for dplInput\n",
    "def train_gen_DAnet(source, target, batch_size):\n",
    "    half = batch_size//2\n",
    "    while True:\n",
    "        source_data, source_lable = source.next()\n",
    "        target_data, target_lable = target.next()\n",
    "        if len(source_lable) != batch_size or len(target_lable) != batch_size:\n",
    "            continue\n",
    "        dpl_data = np.concatenate((source_data[:half,...],target_data[:half,...]),axis=0)\n",
    "               \n",
    "        domain_tmp = np.ones(batch_size, dtype='int8')\n",
    "        domain_tmp[half:] = domain_tmp[half:] * 0\n",
    "        dpl_lable = np.concatenate((domain_tmp.reshape(batch_size,1),\n",
    "                                       np.flip(domain_tmp,0).reshape(batch_size,1)),1)\n",
    "\n",
    "        yield({'lplInput':source_data,'dplInput':dpl_data}, {'lplOut':source_lable,'dplOut':dpl_lable})\n",
    "        \n",
    "def test_gen_DAnet(source, target, batch_size):\n",
    "    half = batch_size//2\n",
    "    while True:\n",
    "        source_data, source_lable = source.next()\n",
    "        target_data, target_lable = target.next()\n",
    "        if len(source_lable) != batch_size or len(target_lable) != batch_size:\n",
    "            continue\n",
    "        dpl_data = np.concatenate((source_data[:half,...],target_data[:half,...]),axis=0)\n",
    "               \n",
    "        domain_tmp = np.ones(batch_size, dtype='int8')\n",
    "        domain_tmp[half:] = domain_tmp[half:] * 0\n",
    "        dpl_lable = np.concatenate((domain_tmp.reshape(batch_size,1),\n",
    "                                       np.flip(domain_tmp,0).reshape(batch_size,1)),1)\n",
    "\n",
    "        yield({'lplInput':target_data,'dplInput':dpl_data}, {'lplOut':target_lable,'dplOut':dpl_lable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in MIQ:\n",
    "    tt\n",
    "    for train_index, test_index in kf.split(n_subjects_phys):\n",
    "        create_data_split(path, test_index)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29772 images belonging to 5 classes.\n",
      "Found 10629 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_gen_source = datagen.flow_from_directory(source_data + '/train', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "train_gen_target = datagen.flow_from_directory(target_data + '/train', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "train_gen_DA = train_gen_DAnet(train_gen_source, train_gen_target, batch_size)\n",
    "\n",
    "train_stepE = np.floor_divide(train_gen_source.n, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4807 images belonging to 5 classes.\n",
      "Found 2838 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_gen_source = datagen.flow_from_directory(source_data + '/validation', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "valid_gen_target = datagen.flow_from_directory(target_data + '/validation', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "valid_gen_DA = test_gen_DAnet(valid_gen_source, valid_gen_target, batch_size)\n",
    "\n",
    "val_stepE = np.floor_divide(valid_gen_source.n, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3862 images belonging to 5 classes.\n",
      "Found 2722 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen_source = datagen.flow_from_directory(source_data + '/test', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "test_gen_target = datagen.flow_from_directory(target_data + '/test', target_size=(224, 224), \n",
    "                                               batch_size=batch_size, class_mode='categorical', shuffle=True)\n",
    "\n",
    "test_gen_DA = test_gen_DAnet(test_gen_source, test_gen_target, batch_size)\n",
    "\n",
    "test_stepE = np.floor_divide(test_gen_source.n, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dplInput (InputLayer)            (None, 224, 224, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 25088)         14714688    lplInput[0][0]                   \n",
      "                                                                   dplInput[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (None, 25088)         0           model_1[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 2048)          51382272    model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (None, 2048)          51382272    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 2048)          0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (None, 2048)          0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 1024)          2098176     lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (None, 1024)          2098176     dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             5125        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (None, 2)             2050        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 121,682,759\n",
      "Trainable params: 121,682,759\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# init. the variable to controle the flipgradient layer\n",
    "lamFunk = K.variable(0.0)\n",
    "current_model = Models.DA_model(lamFunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "csv_logger = CSVLogger('/media/jaskmo/ELEK/bme/Project02456/trainingLog/DA_Model' + \n",
    "                           str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                           str(now.hour) + str(now.minute) + '.log')\n",
    "\n",
    "class FlipControle(Callback):\n",
    "    def __init__(self, alphaIn):\n",
    "        self.alpha = alphaIn\n",
    "        print(K.get_value(lamFunk))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        p = (epoch+1)/nrEpochs\n",
    "        K.set_value(self.alpha, (2/(1+np.exp(-10*p)))-1)\n",
    "        print(K.get_value(lamFunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the S!@Â¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Epoch 1/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 40.3956 - lplOut_loss: 0.4717 - dplOut_loss: 0.1508 - lplOut_categorical_accuracy: 0.8246 - dplOut_categorical_accuracy: 0.94100.462117\n",
      "1488/1488 [==============================] - 1213s - loss: 40.3824 - lplOut_loss: 0.4716 - dplOut_loss: 0.1508 - lplOut_categorical_accuracy: 0.8247 - dplOut_categorical_accuracy: 0.9410 - val_loss: 21.1235 - val_lplOut_loss: 0.4061 - val_dplOut_loss: 0.4954 - val_lplOut_categorical_accuracy: 0.8642 - val_dplOut_categorical_accuracy: 0.8304\n",
      "Epoch 2/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 17.0204 - lplOut_loss: 0.9136 - dplOut_loss: 1.0258 - lplOut_categorical_accuracy: 0.7992 - dplOut_categorical_accuracy: 0.62690.761594\n",
      "1488/1488 [==============================] - 1227s - loss: 17.0174 - lplOut_loss: 0.9131 - dplOut_loss: 1.0256 - lplOut_categorical_accuracy: 0.7993 - dplOut_categorical_accuracy: 0.6267 - val_loss: 12.6670 - val_lplOut_loss: 0.4217 - val_dplOut_loss: 0.7924 - val_lplOut_categorical_accuracy: 0.8488 - val_dplOut_categorical_accuracy: 0.5546\n",
      "Epoch 3/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 10.4343 - lplOut_loss: 0.4366 - dplOut_loss: 0.6949 - lplOut_categorical_accuracy: 0.8407 - dplOut_categorical_accuracy: 0.58480.905148\n",
      "1488/1488 [==============================] - 1231s - loss: 10.4328 - lplOut_loss: 0.4365 - dplOut_loss: 0.6948 - lplOut_categorical_accuracy: 0.8408 - dplOut_categorical_accuracy: 0.5849 - val_loss: 8.7589 - val_lplOut_loss: 0.4615 - val_dplOut_loss: 0.7470 - val_lplOut_categorical_accuracy: 0.8281 - val_dplOut_categorical_accuracy: 0.4960\n",
      "Epoch 4/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 7.4578 - lplOut_loss: 0.4197 - dplOut_loss: 0.6979 - lplOut_categorical_accuracy: 0.8444 - dplOut_categorical_accuracy: 0.57810.964028\n",
      "1488/1488 [==============================] - 1223s - loss: 7.4572 - lplOut_loss: 0.4198 - dplOut_loss: 0.6979 - lplOut_categorical_accuracy: 0.8443 - dplOut_categorical_accuracy: 0.5781 - val_loss: 6.5046 - val_lplOut_loss: 0.4948 - val_dplOut_loss: 0.6914 - val_lplOut_categorical_accuracy: 0.8310 - val_dplOut_categorical_accuracy: 0.6056\n",
      "Epoch 5/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 5.7391 - lplOut_loss: 0.4332 - dplOut_loss: 0.7185 - lplOut_categorical_accuracy: 0.8420 - dplOut_categorical_accuracy: 0.57430.986614\n",
      "1488/1488 [==============================] - 1225s - loss: 5.7387 - lplOut_loss: 0.4331 - dplOut_loss: 0.7186 - lplOut_categorical_accuracy: 0.8420 - dplOut_categorical_accuracy: 0.5743 - val_loss: 5.1661 - val_lplOut_loss: 0.5208 - val_dplOut_loss: 0.6953 - val_lplOut_categorical_accuracy: 0.8360 - val_dplOut_categorical_accuracy: 0.5508\n",
      "Epoch 6/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 4.6410 - lplOut_loss: 0.4446 - dplOut_loss: 0.7339 - lplOut_categorical_accuracy: 0.8398 - dplOut_categorical_accuracy: 0.56820.995055\n",
      "1488/1488 [==============================] - 1226s - loss: 4.6406 - lplOut_loss: 0.4445 - dplOut_loss: 0.7338 - lplOut_categorical_accuracy: 0.8399 - dplOut_categorical_accuracy: 0.5682 - val_loss: 4.2392 - val_lplOut_loss: 0.4911 - val_dplOut_loss: 0.7202 - val_lplOut_categorical_accuracy: 0.8317 - val_dplOut_categorical_accuracy: 0.5363\n",
      "Epoch 7/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 3.7463 - lplOut_loss: 0.3795 - dplOut_loss: 0.6920 - lplOut_categorical_accuracy: 0.8593 - dplOut_categorical_accuracy: 0.57720.998178\n",
      "1488/1488 [==============================] - 1226s - loss: 3.7461 - lplOut_loss: 0.3795 - dplOut_loss: 0.6919 - lplOut_categorical_accuracy: 0.8593 - dplOut_categorical_accuracy: 0.5772 - val_loss: 3.6511 - val_lplOut_loss: 0.5888 - val_dplOut_loss: 0.7059 - val_lplOut_categorical_accuracy: 0.8085 - val_dplOut_categorical_accuracy: 0.5735\n",
      "Epoch 8/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 3.2078 - lplOut_loss: 0.3853 - dplOut_loss: 0.7117 - lplOut_categorical_accuracy: 0.8563 - dplOut_categorical_accuracy: 0.56400.999329\n",
      "1488/1488 [==============================] - 1227s - loss: 3.2075 - lplOut_loss: 0.3851 - dplOut_loss: 0.7117 - lplOut_categorical_accuracy: 0.8564 - dplOut_categorical_accuracy: 0.5639 - val_loss: 3.1518 - val_lplOut_loss: 0.4976 - val_dplOut_loss: 0.7601 - val_lplOut_categorical_accuracy: 0.8485 - val_dplOut_categorical_accuracy: 0.5194\n",
      "Epoch 9/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 2.8056 - lplOut_loss: 0.3711 - dplOut_loss: 0.7119 - lplOut_categorical_accuracy: 0.8629 - dplOut_categorical_accuracy: 0.56550.999753\n",
      "1488/1488 [==============================] - 1226s - loss: 2.8057 - lplOut_loss: 0.3712 - dplOut_loss: 0.7119 - lplOut_categorical_accuracy: 0.8629 - dplOut_categorical_accuracy: 0.5655 - val_loss: 2.8254 - val_lplOut_loss: 0.4342 - val_dplOut_loss: 0.8232 - val_lplOut_categorical_accuracy: 0.8496 - val_dplOut_categorical_accuracy: 0.4973\n",
      "Epoch 10/10\n",
      "1487/1488 [============================>.] - ETA: 0s - loss: 2.4876 - lplOut_loss: 0.3483 - dplOut_loss: 0.6964 - lplOut_categorical_accuracy: 0.8704 - dplOut_categorical_accuracy: 0.56630.999909\n",
      "1488/1488 [==============================] - 1226s - loss: 2.4874 - lplOut_loss: 0.3482 - dplOut_loss: 0.6964 - lplOut_categorical_accuracy: 0.8704 - dplOut_categorical_accuracy: 0.5662 - val_loss: 2.5263 - val_lplOut_loss: 0.4564 - val_dplOut_loss: 0.7401 - val_lplOut_categorical_accuracy: 0.8481 - val_dplOut_categorical_accuracy: 0.5040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81680b9e48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model.fit_generator(train_gen_DA, train_stepE, epochs=nrEpochs, verbose=1, validation_data=test_gen_DA, \n",
    "                            validation_steps=val_stepE, callbacks=[csv_logger,FlipControle(lamFunk)], initial_epoch=0,\n",
    "                            max_queue_size=2)\n",
    "\n",
    "if MIQ == \"DA\":\n",
    "    DAlpm = utils.dissect_DAlpm(current_model)\n",
    "    current_model = DAlpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "    \n",
    "current_model.save(filepath=path + 'models/'+ MIQ + str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                       str(now.hour) + str(now.minute) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img, test_lable = test_gen_target.next()\n",
    "for count in range(test_gen_target.n//batch_size):\n",
    "    tmp_img, tmp_lable = test_gen_target.next()\n",
    "    test_img = np.concatenate((test_img, tmp_img), axis=0)\n",
    "    test_lable = np.concatenate((test_lable, tmp_lable),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the test metrecis \n",
    "inv_map = {v: k for k, v in test_gen_target.class_indices.items()}\n",
    "target_names = list(inv_map.values())\n",
    "\n",
    "targets_test_int = [np.where(r == 1)[0][0] for r in test_lable]\n",
    "y_pred = mod.predict(test_img)\n",
    "y_pred2 = np.argmax(y_pred, axis = 1)\n",
    "# Test accuracy:\n",
    "acc = accuracy_score(targets_test_int, y_pred2)\n",
    "print('Accuracy on target domain = ', acc)\n",
    "\n",
    "conf_mat = confusion_matrix(targets_test_int, y_pred2)\n",
    "print(conf_mat)\n",
    "# Per class metrics\n",
    "class_report = classification_report(targets_test_int, y_pred2, target_names=target_names)\n",
    "print(class_report)\n",
    "\n",
    "# save to file \n",
    "test_file = '/media/jaskmo/ELEK/bme/Project02456/testLog/DA_Model' + str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + str(now.hour) + str(now.minute) + '.log'\n",
    "\n",
    "sys.stdout = open(test_file, 'w')\n",
    "\n",
    "print('Accuracy on target domain = ' + str(acc) +'\\n \\n' + \n",
    "      'Confution matric on target domain: \\n' + str(conf_mat) + '\\n\\n' + \n",
    "      'Class report on target domain: \\n' + class_report)\n",
    "\n",
    "sys.stdout = stdout_cell\n",
    "\n",
    "# Evaluate error on source data\n",
    "# _, metric = current_model.evaluate_generator(generator=test_gen_DA, steps=test_stepE)\n",
    "# print('Accuracy on source domain = ', metric)\n",
    "\n",
    "    \n",
    "# elif training_mode == 'target': # Training on target data from hospital\n",
    "#     # Convert from onehot\n",
    "#     targets_test_int = [np.where(r == 1)[0][0] for r in targets_test_hosp]\n",
    "#     y_pred = current_model.predict(inputs_test_hosp)\n",
    "#     y_pred2 = np.argmax(y_pred, axis = 1)\n",
    "#     # Test accuracy:\n",
    "#     acc = accuracy_score(targets_test_int, y_pred2)\n",
    "#     print('Accuracy in this domain = ', acc)\n",
    "#     # Confusion matrix for target\n",
    "#     conf_mat = confusion_matrix(targets_test_int, y_pred2)\n",
    "#     print(conf_mat)\n",
    "#     # Per class metrics\n",
    "#     class_report = classification_report(targets_test_int, y_pred2, target_names=target_names)\n",
    "#     print(class_report)\n",
    "    \n",
    "#     # Evaluate error on source data\n",
    "#     _, metric = current_model.evaluate(x=inputs_test_phys, y=targets_test_phys, batch_size=50)\n",
    "#     print('Accuracy on other domain = ', metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
