{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger\n",
    "from datetime import datetime\n",
    "import extras.ourUtils\n",
    "import numpy as np\n",
    "import Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "full_train = True\n",
    "path = '/home/jaskmo/Documents/programering/02456DomainAdaptation/'\n",
    "source_data = path + 'taperImages/pysNetData'\n",
    "target_data = path + 'taperImages/hData'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data as generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# make a joint generator form a Physionet generator and a Hospital generator\n",
    "def gen_DAnet(source, target, LL=batch_size, train=True):\n",
    "    domain_tmp = np.ones(LL, dtype='int8')\n",
    "    domain_tmp[int(LL/2):] = domain_tmp[int(LL/2):] * 0\n",
    "    domain_lable = np.concatenate((domain_tmp.reshape(LL,1),np.flip(domain_tmp,0).reshape(LL,1)),1)\n",
    "    while True:\n",
    "        if train:\n",
    "            source_data, source_lable = source.next()\n",
    "            target_data, target_lable = target.next()\n",
    "            DA_data = np.concatenate((source_data,target_data),axis=0)\n",
    "            class_lable = source_lable\n",
    "            \n",
    "            yield(DA_data, {'lplOut':class_lable,'dplOut':domain_lable})\n",
    "        else:\n",
    "            source_data, source_lable = source.next()\n",
    "            target_data, target_lable = target.next()\n",
    "            DA_data = np.concatenate((source_data,target_data),axis=0)\n",
    "            class_lable = np.concatenate((source_lable,target_lable),axis=0)\n",
    "        \n",
    "            yield(DA_data, {'lplOut':class_lable,'dplOut':domain_lable})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29772 images belonging to 5 classes.\n",
      "Found 10629 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_gen_source = datagen.flow_from_directory(source_data + '/train', target_size=(224, 224), \n",
    "                                               batch_size=int(np.floor_divide(batch_size,2)), \n",
    "                                               class_mode='categorical', shuffle=True)\n",
    "train_gen_target = datagen.flow_from_directory(target_data + '/train', target_size=(224, 224), \n",
    "                                               batch_size=int(np.floor_divide(batch_size,2)), \n",
    "                                               class_mode='categorical', shuffle=True)\n",
    "# init gen_DAnet\n",
    "train_gen_DAnet = gen_DAnet(source=train_gen_source, target=train_gen_target, LL=batch_size)\n",
    "\n",
    "train_stepE = np.floor_divide(train_gen_source.n, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4807 images belonging to 5 classes.\n",
      "Found 2838 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_gen_source = datagen.flow_from_directory(source_data + '/validation', target_size=(224, 224), \n",
    "                                               batch_size=int(np.floor_divide(batch_size,2)), \n",
    "                                               class_mode='categorical', shuffle=True)\n",
    "valid_gen_target = datagen.flow_from_directory(target_data + '/validation', target_size=(224, 224), \n",
    "                                               batch_size=int(np.floor_divide(batch_size,2)), \n",
    "                                               class_mode='categorical', shuffle=True)\n",
    "# init gen_DAnet\n",
    "valid_gen_DAnet = gen_DAnet(source=valid_gen_source, target=valid_gen_target, LL=batch_size)\n",
    "\n",
    "val_stepE = np.floor_divide(valid_gen_source.n, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3862 images belonging to 5 classes.\n",
      "Found 2722 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen_source = datagen.flow_from_directory(source_data + '/test', target_size=(224, 224), \n",
    "                                               batch_size=int(np.floor_divide(batch_size,2)), \n",
    "                                               class_mode='categorical', shuffle=True)\n",
    "test_gen_target = datagen.flow_from_directory(target_data + '/test', target_size=(224, 224), \n",
    "                                               batch_size=int(np.floor_divide(batch_size,2)), \n",
    "                                               class_mode='categorical', shuffle=True)\n",
    "# init gen_DAnet\n",
    "test_gen_DAnet = gen_DAnet(source=test_gen_source, target=test_gen_target, LL=batch_size)\n",
    "\n",
    "test_stepE = np.floor_divide(test_gen_source.n, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "image_input (InputLayer)         (40, 224, 224, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "vgg16 (Model)                    multiple              14714688    image_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "preDa (Flatten)                  (40, 25088)           0           vgg16[1][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lplSplit (Lambda)                (None, 25088)         0           preDa[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flipGrad (Lambda)                (40, 25088)           0           preDa[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "lpl1 (Dense)                     (None, 2048)          51382272    lplSplit[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dpl1 (Dense)                     (40, 2048)            51382272    flipGrad[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lpl1Do (Dropout)                 (None, 2048)          0           lpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dpl1Do (Dropout)                 (40, 2048)            0           dpl1[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "lpl2 (Dense)                     (None, 1024)          2098176     lpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dpl2 (Dense)                     (40, 1024)            2098176     dpl1Do[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lplOut (Dense)                   (None, 5)             5125        lpl2[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "dplOut (Dense)                   (40, 2)               2050        dpl2[0][0]                       \n",
      "====================================================================================================\n",
      "Total params: 121,682,759\n",
      "Trainable params: 121,682,759\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "current_model = Models.DA_model(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "csv_logger = CSVLogger('/media/jaskmo/ELEK/bme/Project02456/trainingLog/DA_Model' + \n",
    "                           str(now.day) + '-' + str(now.month) + '-' + str(now.year) + '_' + \n",
    "                           str(now.hour) + str(now.minute) + '.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the S!@¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All target arrays (y) should have the same number of samples. Got array shapes: [(20, 5), (40, 2)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2b2cdb58cb3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m current_model.fit_generator(test_gen_DAnet, steps_per_epoch=train_stepE, validation_data=valid_gen_DAnet, \n\u001b[0;32m----> 2\u001b[0;31m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_stepE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                             )#class_weight=weights_dic)\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2041\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1388\u001b[0m                           \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m                           in zip(y, sample_weights, class_weights, self._feed_sample_weight_modes)]\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0m_check_array_lengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m         _check_loss_and_target_compatibility(y,\n\u001b[1;32m   1392\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_loss_fns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_check_array_lengths\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError('All target arrays (y) should have '\n\u001b[1;32m    235\u001b[0m                          \u001b[0;34m'the same number of samples. Got array shapes: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                          str([y.shape for y in targets]))\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mset_x\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mset_y\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         raise ValueError('Input arrays should have '\n",
      "\u001b[0;31mValueError\u001b[0m: All target arrays (y) should have the same number of samples. Got array shapes: [(20, 5), (40, 2)]"
     ]
    }
   ],
   "source": [
    "current_model.fit_generator(test_gen_DAnet, steps_per_epoch=train_stepE, validation_data=valid_gen_DAnet, \n",
    "                            validation_steps=val_stepE, epochs=10, verbose=1, callbacks=[csv_logger], \n",
    "                            )#class_weight=weights_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
